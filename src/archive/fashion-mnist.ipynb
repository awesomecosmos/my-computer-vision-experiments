{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion-MNIST Experiment\n",
    "\n",
    "In this notebook, I will use the [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset and build my own CNN from scratch. I'm following [this tutorial](https://pytorch.org/tutorials/beginner/introyt/trainingyt.html?highlight=nn%20crossentropyloss), but typing it out myself and really understand what's going on at every line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "# Class labels\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# Report split sizes\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.FashionMNIST"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "2\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([4, 1, 28, 28])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(training_loader)\n",
    "data = next(dataiter)\n",
    "print(type(data))  # Should be a tuple or list\n",
    "print(len(data))   # Should be 2 (images and labels)\n",
    "images, labels = data\n",
    "print(type(images))  # Should be a tensor\n",
    "print(images.shape)  # Check the shape of the tensor\n",
    "print(type(labels))  # Should be a tensor or list/array\n",
    "print(labels.shape)  # Check the shape of the labels tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag  Sandal  T-shirt/top  Pullover\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "print('  '.join(classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inheriting the Module class, which is a fundamental building block of any NN in PyTorch\n",
    "class FashionClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        # properly initiaitlizing the class by ensuring it is a super class\n",
    "        super(FashionClassifier, self).__init__()\n",
    "\n",
    "        # defining our first convolution\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1, # number of input feature maps (btw channels=feature maps in this context)\n",
    "            out_channels=6, # number of output feature maps (QUESTION: can I change this as a hyperparameter? how did they select 6?)\n",
    "            kernel_size=5 # nxn size of kernel, in this case it's 5x5\n",
    "            )\n",
    "        # defining a pooling method\n",
    "        self.pool = nn.MaxPool2d( # max pooling\n",
    "            kernel_size=2, # using 2x2 kernel\n",
    "            stride=2 \n",
    "        )\n",
    "        # defining our second convolution\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=6, # 6 input feature maps from conv1's output\n",
    "            out_channels=16, # 16 output feature maps\n",
    "            kernel_size=5 # again, 5x5 kernel\n",
    "        )\n",
    "        # defining our first fully-connected (dense) layer\n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features=16*4*4, # 16 feature maps from the previous convolution, which are each of size 4*4 for a total of 256 features\n",
    "            out_features=120\n",
    "        )\n",
    "        self.fc2 = nn.Linear(\n",
    "            in_features=120, # again, taking as input 120 from the last FC layer's output\n",
    "            out_features=84\n",
    "        )\n",
    "        self.fc3 = nn.Linear(\n",
    "            in_features=84,\n",
    "            out_features=10 # we have only 10 output features here because we have 10 classes\n",
    "        )\n",
    "\n",
    "    # defining our forward pass with the methods defined above\n",
    "    def forward(self, x):\n",
    "        # first block\n",
    "        # conv1 -> ReLU -> maxPool\n",
    "        x = self.pool(\n",
    "            F.relu(\n",
    "                self.conv1(x)\n",
    "            )\n",
    "        )\n",
    "        # second block\n",
    "        # conv2 -> ReLU -> maxPool\n",
    "        x = self.pool(\n",
    "            F.relu(\n",
    "                self.conv2(x)\n",
    "            )\n",
    "        )\n",
    "        x = x.view(\n",
    "            # method to reshape the output tensor after convolutions into 2D\n",
    "            -1, # -1 is a special parameter to automatically determine the batch size\n",
    "            16 * 4 * 4 # this is  the size of the original tensor\n",
    "        )\n",
    "        # feeding the flattened feature map to the fully-connected layers\n",
    "        # first FC layer\n",
    "        # FC -> ReLU\n",
    "        x = F.relu(\n",
    "            self.fc1(x)\n",
    "        )\n",
    "        # same here\n",
    "        x = F.relu(\n",
    "            self.fc2(x)\n",
    "        )\n",
    "        # no ReLU on last layer\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so I think I better understand the architecture for this specific example. I learned about how the dimensions of the input/output feature maps evolve over the different layers. For now, I have left the exact architecture they specified in the [tutorial](https://pytorch.org/tutorials/beginner/introyt/trainingyt.html?highlight=nn%20crossentropyloss), but I want to play with this architecture and see what happens. I will first continue with the tutorial as-is, and then experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating the model\n",
    "fashion_classifier_model = FashionClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss() # why not binary cross-entropy? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# they used SGD as their optimizer here\n",
    "# why not any other optimzier?\n",
    "optimizer = torch.optim.SGD(\n",
    "    params=fashion_classifier_model.parameters(), # using all of model's parameters to optimize over\n",
    "    lr=0.001, # this is the learning rate - experiment with this\n",
    "    momentum=0.9 # setting momentum\n",
    "    # what about other parameters? e.g. weight decay, dropout?\n",
    "    # experiment with the params listed here, and also adding/removing combinations of hyperparams\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0\n",
    "    last_loss = 0\n",
    "\n",
    "    for i, data in enumerate(training_loader):\n",
    "        inputs, labels = data\n",
    "        # setting the gradients to zero for this run\n",
    "        optimizer.zero_grad()\n",
    "        # passing the data to the model as input\n",
    "        outputs = fashion_classifier_model(inputs)\n",
    "        # computing loss for outputs\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        # performing back-propagation\n",
    "        loss.backward()\n",
    "        # adjusting weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # recording data and printing to console\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000\n",
    "            print(f\"batch {i+1} loss: {last_loss}\")\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar(\"Loss/train\", last_loss, tb_x)\n",
    "            running_loss = 0\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Epoch Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "batch 1000 loss: 0.24547620160983116\n",
      "batch 2000 loss: 0.25997000668839065\n",
      "batch 3000 loss: 0.25920666188115865\n",
      "batch 4000 loss: 0.26747941748098036\n",
      "batch 5000 loss: 0.2712163886357557\n",
      "batch 6000 loss: 0.25745894092694654\n",
      "batch 7000 loss: 0.25633522334253167\n",
      "batch 8000 loss: 0.25864687859453056\n",
      "batch 9000 loss: 0.25633405176803353\n",
      "batch 10000 loss: 0.26053834167071727\n",
      "batch 11000 loss: 0.26533620671688\n",
      "batch 12000 loss: 0.2452705443614202\n",
      "batch 13000 loss: 0.2575557631535212\n",
      "batch 14000 loss: 0.2601004553446473\n",
      "batch 15000 loss: 0.256349997115115\n",
      "LOSS train 0.256349997115115 valid 0.3052155375480652\n",
      "Epoch 2:\n",
      "batch 1000 loss: 0.2284957202244077\n",
      "batch 2000 loss: 0.2525983544543783\n",
      "batch 3000 loss: 0.2503843576388726\n",
      "batch 4000 loss: 0.24429637947289667\n",
      "batch 5000 loss: 0.23718814242766928\n",
      "batch 6000 loss: 0.23908485483687855\n",
      "batch 7000 loss: 0.25146247519589227\n",
      "batch 8000 loss: 0.25485871250147646\n",
      "batch 9000 loss: 0.2741635209045589\n",
      "batch 10000 loss: 0.23164373057127113\n",
      "batch 11000 loss: 0.25576468524364326\n",
      "batch 12000 loss: 0.24826789548019587\n",
      "batch 13000 loss: 0.25953755890487085\n",
      "batch 14000 loss: 0.25200652266415274\n",
      "batch 15000 loss: 0.259332675936972\n",
      "LOSS train 0.259332675936972 valid 0.3155205547809601\n",
      "Epoch 3:\n",
      "batch 1000 loss: 0.233387842963828\n",
      "batch 2000 loss: 0.2365492288332971\n",
      "batch 3000 loss: 0.22627161561346293\n",
      "batch 4000 loss: 0.24794242431497332\n",
      "batch 5000 loss: 0.23389595709021205\n",
      "batch 6000 loss: 0.22585970800560426\n",
      "batch 7000 loss: 0.23407167200002005\n",
      "batch 8000 loss: 0.22418963583546975\n",
      "batch 9000 loss: 0.25034876523596267\n",
      "batch 10000 loss: 0.25004712261335954\n",
      "batch 11000 loss: 0.22443792156618292\n",
      "batch 12000 loss: 0.24363583192063198\n",
      "batch 13000 loss: 0.23532217469497027\n",
      "batch 14000 loss: 0.26535254347534554\n",
      "batch 15000 loss: 0.23634659570845906\n",
      "LOSS train 0.23634659570845906 valid 0.3017982244491577\n",
      "Epoch 4:\n",
      "batch 1000 loss: 0.2369931926795839\n",
      "batch 2000 loss: 0.23409343934144816\n",
      "batch 3000 loss: 0.21388093341128114\n",
      "batch 4000 loss: 0.21995786641006818\n",
      "batch 5000 loss: 0.23027880590709776\n",
      "batch 6000 loss: 0.2310299289380928\n",
      "batch 7000 loss: 0.23288766937984157\n",
      "batch 8000 loss: 0.21652209955378623\n",
      "batch 9000 loss: 0.22772663431055493\n",
      "batch 10000 loss: 0.23523100703379124\n",
      "batch 11000 loss: 0.22346988734493062\n",
      "batch 12000 loss: 0.2245699762055501\n",
      "batch 13000 loss: 0.24710009214815182\n",
      "batch 14000 loss: 0.21674219264619296\n",
      "batch 15000 loss: 0.2359516118777003\n",
      "LOSS train 0.2359516118777003 valid 0.29088857769966125\n",
      "Epoch 5:\n",
      "batch 1000 loss: 0.21859169441899212\n",
      "batch 2000 loss: 0.19963596610976173\n",
      "batch 3000 loss: 0.2191055690054672\n",
      "batch 4000 loss: 0.1989477086162425\n",
      "batch 5000 loss: 0.22079641634874997\n",
      "batch 6000 loss: 0.20868934662958646\n",
      "batch 7000 loss: 0.2203663915772504\n",
      "batch 8000 loss: 0.2143791450607041\n",
      "batch 9000 loss: 0.2293647162613097\n",
      "batch 10000 loss: 0.23018305040461656\n",
      "batch 11000 loss: 0.21741832819651064\n",
      "batch 12000 loss: 0.21326482216763498\n",
      "batch 13000 loss: 0.22877526127521106\n",
      "batch 14000 loss: 0.23299074522448562\n",
      "batch 15000 loss: 0.23563722487094527\n",
      "LOSS train 0.23563722487094527 valid 0.2966734766960144\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter(f'runs/fashion_trainer_{timestamp}')\n",
    "epoch_number = 0\n",
    "\n",
    "# setting global variable of EPOCHS\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {(epoch_number + 1)}:')\n",
    "    fashion_classifier_model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    fashion_classifier_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = fashion_classifier_model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "        \n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print(f'LOSS train {avg_loss} valid {avg_vloss}')\n",
    "\n",
    "    writer.add_scalars(\n",
    "        'Training vs Validation Loss',\n",
    "        {'Training':avg_loss, 'Validation':avg_vloss},\n",
    "        epoch_number+1\n",
    "    )\n",
    "    writer.flush()\n",
    "\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = f'../models/model_{timestamp}_{epoch_number}'\n",
    "        torch.save(fashion_classifier_model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
