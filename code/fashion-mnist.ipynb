{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion-MNIST Experiment\n",
    "\n",
    "In this notebook, I will use the [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset and build my own CNN from scratch. I'm following [this tutorial](https://pytorch.org/tutorials/beginner/introyt/trainingyt.html?highlight=nn%20crossentropyloss), but typing it out myself and really understand what's going on at every line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m transform \u001b[38;5;241m=\u001b[39m \u001b[43mtransforms\u001b[49m\u001b[38;5;241m.\u001b[39mCompose(\n\u001b[1;32m      2\u001b[0m     [transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[1;32m      3\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize((\u001b[38;5;241m0.5\u001b[39m,), (\u001b[38;5;241m0.5\u001b[39m,))])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class labels\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# Report split sizes\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(training_loader)\n",
    "data = next(dataiter)\n",
    "print(type(data))  # Should be a tuple or list\n",
    "print(len(data))   # Should be 2 (images and labels)\n",
    "images, labels = data\n",
    "print(type(images))  # Should be a tensor\n",
    "print(images.shape)  # Check the shape of the tensor\n",
    "print(type(labels))  # Should be a tensor or list/array\n",
    "print(labels.shape)  # Check the shape of the labels tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "print('  '.join(classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inheriting the Module class, which is a fundamental building block of any NN in PyTorch\n",
    "class FashionClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        # properly initiaitlizing the class by ensuring it is a super class\n",
    "        super(FashionClassifier, self).__init__()\n",
    "\n",
    "        # defining our first convolution\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1, # number of input feature maps (btw channels=feature maps in this context)\n",
    "            out_channels=6, # number of output feature maps (QUESTION: can I change this as a hyperparameter? how did they select 6?)\n",
    "            kernel_size=5 # nxn size of kernel, in this case it's 5x5\n",
    "            )\n",
    "        # defining a pooling method\n",
    "        self.pool = nn.MaxPool2d( # max pooling\n",
    "            kernel_size=2, # using 2x2 kernel\n",
    "            stride=2 \n",
    "        )\n",
    "        # defining our second convolution\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=6, # 6 input feature maps from conv1's output\n",
    "            out_channels=16, # 16 output feature maps\n",
    "            kernel_size=5 # again, 5x5 kernel\n",
    "        )\n",
    "        # defining our first fully-connected (dense) layer\n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features=16*4*4, # 16 feature maps from the previous convolution, which are each of size 4*4 for a total of 256 features\n",
    "            out_features=120\n",
    "        )\n",
    "        self.fc2 = nn.Linear(\n",
    "            in_features=120, # again, taking as input 120 from the last FC layer's output\n",
    "            out_features=84\n",
    "        )\n",
    "        self.fc3 = nn.Linear(\n",
    "            in_features=84,\n",
    "            out_features=10 # we have only 10 output features here because we have 10 classes\n",
    "        )\n",
    "\n",
    "        # defining our forward pass with the methods defined above\n",
    "        def forward(self, x):\n",
    "            # first block\n",
    "            # conv1 -> ReLU -> maxPool\n",
    "            x = self.pool(\n",
    "                F.relu(\n",
    "                    self.conv1(x)\n",
    "                )\n",
    "            )\n",
    "            # second block\n",
    "            # conv2 -> ReLU -> maxPool\n",
    "            x = self.pool(\n",
    "                F.relu(\n",
    "                    self.conv2(x)\n",
    "                )\n",
    "            )\n",
    "            x = x.view(\n",
    "                # method to reshape the output tensor after convolutions into 2D\n",
    "                -1, # -1 is a special parameter to automatically determine the batch size\n",
    "                16 * 4 * 4 # this is  the size of the original tensor\n",
    "            )\n",
    "            # feeding the flattened feature map to the fully-connected layers\n",
    "            # first FC layer\n",
    "            # FC -> ReLU\n",
    "            x = F.relu(\n",
    "                self.fc1(x)\n",
    "            )\n",
    "            # same here\n",
    "            x = F.relu(\n",
    "                self.fc2(x)\n",
    "            )\n",
    "            # no ReLU on last layer\n",
    "            x = self.fc3(x)\n",
    "\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so I think I better understand the architecture for this specific example. I learned about how the dimensions of the input/output feature maps evolve over the different layers. For now, I have left the exact architecture they specified in the [tutorial](https://pytorch.org/tutorials/beginner/introyt/trainingyt.html?highlight=nn%20crossentropyloss), but I want to play with this architecture and see what happens. I will first continue with the tutorial as-is, and then experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating the model\n",
    "fashion_classifier_model = FashionClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss() # why not binary cross-entropy? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# they used SGD as their optimizer here\n",
    "# why not any other optimzier?\n",
    "optimizer = torch.optim.SGD(\n",
    "    params=fashion_classifier_model.parameters(), # using all of model's parameters to optimize over\n",
    "    lr=0.001, # this is the learning rate - experiment with this\n",
    "    momentum=0.9 # setting momentum\n",
    "    # what about other parameters? e.g. weight decay, dropout?\n",
    "    # experiment with the params listed here, and also adding/removing combinations of hyperparams\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0\n",
    "    last_loss = 0\n",
    "\n",
    "    for i, data in enumerate(training_loader):\n",
    "        inputs, labels = data\n",
    "        # setting the gradients to zero for this run\n",
    "        optimizer.zero_grad()\n",
    "        # passing the data to the model as input\n",
    "        outputs = fashion_classifier_model(inputs)\n",
    "        # computing loss for outputs\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        # performing back-propagation\n",
    "        loss.backward()\n",
    "        # adjusting weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # recording data and printing to console\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000\n",
    "            print(f\"batch {i+1} loss: {last_loss}\")\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar(\"Loss/train\", last_loss, tb_x)\n",
    "            running_loss = 0\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Epoch Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter(f'runs/fashion_trainer_{timestamp}')\n",
    "epoch_number = 0\n",
    "\n",
    "# setting global variable of EPOCHS\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {(epoch_number + 1)}:')\n",
    "    fashion_classifier_model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    fashion_classifier_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = fashion_classifier_model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "        \n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print(f'LOSS train {avg_loss} valid {avg_vloss}')\n",
    "\n",
    "    writer.add_scalars(\n",
    "        'Training vs Validation Loss',\n",
    "        {'Training':avg_loss, 'Validation':avg_vloss},\n",
    "        epoch_number+1\n",
    "    )\n",
    "    writer.flush()\n",
    "\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = f'model_{timestamp}_{epoch_number}'\n",
    "        torch.save(fashion_classifier_model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
