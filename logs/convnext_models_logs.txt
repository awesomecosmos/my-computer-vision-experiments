2025-03-31 21:22:54 - Running script: convnext.py
2025-03-31 21:22:54 - Script started at: 2025-03-31 21:22:54
2025-03-31 21:22:54 - Using device: cuda
2025-03-31 21:22:54 - Starting new experiment!
2025-03-31 21:22:54 - {
    "model_name": "ConvNeXt-Tiny",
    "pretrained_model": true,
    "finetuning": false,
    "batchSize": 64,
    "n_epochs": 2,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 21:22:57 - Training model: (ConvNeXt-Tiny, pretrained=True, finetuning=False, optimizer=Adam)
2025-03-31 21:25:37 - Epoch 1/2, Loss: 0.4304, Accuracy: 85.0867%
2025-03-31 21:28:14 - Epoch 2/2, Loss: 0.3298, Accuracy: 88.3000%
2025-03-31 21:28:57 - Running script: convnext.py
2025-03-31 21:28:57 - Script started at: 2025-03-31 21:28:57
2025-03-31 21:28:57 - Using device: cuda
2025-03-31 21:28:57 - Starting new experiment!
2025-03-31 21:28:57 - {
    "model_name": "ConvNeXt-Tiny",
    "pretrained_model": true,
    "finetuning": false,
    "batchSize": 64,
    "n_epochs": 2,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 21:28:58 - Training model: (ConvNeXt-Tiny, pretrained=True, finetuning=False, optimizer=Adam)
2025-03-31 21:31:35 - Epoch 1/2, Loss: 0.4286, Accuracy: 85.2950%
2025-03-31 21:34:11 - Epoch 2/2, Loss: 0.3316, Accuracy: 88.2833%
2025-03-31 21:34:36 - Test Accuracy: 88.06%
2025-03-31 21:34:36 - Saved numerical results in pickle!
2025-03-31 21:34:36 - Saved numerical results in pickle!
2025-03-31 21:34:36 - Total execution time: 339.41 seconds
2025-03-31 21:40:04 - ==================================================
2025-03-31 21:40:04 - Running script: convnext.py
2025-03-31 21:40:04 - Script started at: 2025-03-31 21:40:04
2025-03-31 21:40:04 - Using device: cuda
2025-03-31 21:40:04 - CUDA Device Total Memory [GB]:25.380061184
2025-03-31 21:40:04 - Starting new experiment!
2025-03-31 21:40:04 - {
    "model_name": "ConvNeXt-Tiny",
    "pretrained_model": true,
    "finetuning": false,
    "batchSize": 64,
    "n_epochs": 2,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 21:40:04 - Training model: (ConvNeXt-Tiny, pretrained=True, finetuning=False, optimizer=Adam)
2025-03-31 21:42:40 - Epoch 1/2, Loss: 0.4329, Accuracy: 85.0667%
2025-03-31 21:45:15 - Epoch 2/2, Loss: 0.3316, Accuracy: 88.2500%
2025-03-31 21:45:40 - Test Accuracy: 88.17%
2025-03-31 21:45:40 - Saved numerical results in pickle!
2025-03-31 21:45:55 - ==================================================
2025-03-31 21:45:55 - Running script: convnext.py
2025-03-31 21:45:55 - Script started at: 2025-03-31 21:45:55
2025-03-31 21:45:55 - Using device: cuda
2025-03-31 21:45:55 - CUDA Device Total Memory [GB]:25.380061184
2025-03-31 21:45:55 - Starting new experiment!
2025-03-31 21:45:55 - {
    "model_name": "ConvNeXt-Tiny",
    "pretrained_model": true,
    "finetuning": false,
    "batchSize": 64,
    "n_epochs": 2,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 21:45:56 - Training model: (ConvNeXt-Tiny, pretrained=True, finetuning=False, optimizer=Adam)
2025-03-31 21:48:33 - Epoch 1/2, Loss: 0.4285, Accuracy: 85.1183%
2025-03-31 21:51:09 - Epoch 2/2, Loss: 0.3304, Accuracy: 88.2500%
2025-03-31 21:51:34 - Test Accuracy: 88.29%
2025-03-31 21:51:34 - Saved numerical results in pickle!
2025-03-31 21:52:01 - Saved numerical results in pickle!
2025-03-31 21:52:01 - Script ended at: 2025-03-31 21:52:01
2025-03-31 21:52:01 - Total execution time: 365.81 seconds
2025-03-31 21:52:01 - ==================================================
2025-04-01 09:07:12 - ==================================================
2025-04-01 09:07:12 - Running script: convnext.py
2025-04-01 09:07:12 - Script started at: 2025-04-01 09:07:12
2025-04-01 09:07:12 - Using device: cuda
2025-04-01 09:07:12 - CUDA Device Total Memory [GB]:50.936283136
2025-04-01 09:07:12 - Starting new experiment!
2025-04-01 09:07:12 - {
    "model_name": "ConvNeXt-Tiny",
    "pretrained_model": true,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-01 09:07:15 - Training model: (ConvNeXt-Tiny, pretrained=True, finetuning=True, optimizer=Adam)
2025-04-01 09:09:15 - Epoch 1/10, Loss: 0.4325, Accuracy: 85.1600%
2025-04-01 09:11:15 - Epoch 2/10, Loss: 0.3310, Accuracy: 88.3883%
2025-04-01 09:13:17 - Epoch 3/10, Loss: 0.3152, Accuracy: 89.0683%
2025-04-01 09:15:18 - Epoch 4/10, Loss: 0.3061, Accuracy: 89.3917%
2025-04-01 09:17:20 - Epoch 5/10, Loss: 0.3063, Accuracy: 89.3717%
2025-04-01 09:19:22 - Epoch 6/10, Loss: 0.2968, Accuracy: 89.6417%
2025-04-01 09:21:24 - Epoch 7/10, Loss: 0.2907, Accuracy: 89.8967%
2025-04-01 09:23:27 - Epoch 8/10, Loss: 0.2880, Accuracy: 90.0467%
2025-04-01 09:25:28 - Epoch 9/10, Loss: 0.2881, Accuracy: 90.0617%
2025-04-01 09:27:30 - Epoch 10/10, Loss: 0.2863, Accuracy: 90.0967%
2025-04-01 09:27:47 - Test Accuracy: 89.72%
2025-04-01 09:42:47 - ==================================================
2025-04-01 09:42:47 - Running script: convnext.py
2025-04-01 09:42:47 - Script started at: 2025-04-01 09:42:47
2025-04-01 09:42:47 - Using device: cuda
2025-04-01 09:42:47 - CUDA Device Total Memory [GB]:50.936283136
2025-04-01 09:42:47 - Starting new experiment!
2025-04-01 09:42:47 - {
    "model_name": "ConvNeXt-Tiny",
    "pretrained_model": true,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-01 09:42:48 - Training model: (ConvNeXt-Tiny, pretrained=True, finetuning=True, optimizer=Adam)
2025-04-01 09:43:55 - ==================================================
2025-04-01 09:43:55 - Running script: convnext.py
2025-04-01 09:43:55 - Script started at: 2025-04-01 09:43:55
2025-04-01 09:43:55 - Using device: cuda
2025-04-01 09:43:55 - CUDA Device Total Memory [GB]:50.936283136
2025-04-01 09:43:55 - Starting new experiment!
2025-04-01 09:43:55 - {
    "model_name": "ConvNeXt-Tiny",
    "pretrained_model": true,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-01 09:43:56 - Training model: (ConvNeXt-Tiny, pretrained=True, finetuning=True, optimizer=Adam)
2025-04-01 09:45:56 - Epoch 1/1, Loss: 0.4281, Accuracy: 85.2700%
2025-04-01 09:46:12 - Test Accuracy: 87.55%
2025-04-01 09:46:12 - Saved numerical results in pickle!
2025-04-01 09:47:52 - ==================================================
2025-04-01 09:47:52 - Running script: convnext.py
2025-04-01 09:47:52 - Script started at: 2025-04-01 09:47:52
2025-04-01 09:47:52 - Using device: cuda
2025-04-01 09:47:52 - CUDA Device Total Memory [GB]:50.936283136
2025-04-01 09:47:52 - Starting new experiment!
2025-04-01 09:47:52 - {
    "model_name": "ConvNeXt-Tiny",
    "pretrained_model": true,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-01 09:47:53 - Training model: (ConvNeXt-Tiny, pretrained=True, finetuning=True, optimizer=Adam)
2025-04-01 09:47:53 - Starting training!
2025-04-01 09:49:54 - Epoch 1/1, Loss: 0.4326, Accuracy: 85.0533%
2025-04-01 09:49:54 - Testing model!
2025-04-01 09:50:10 - Test Accuracy: 87.77%
2025-04-01 09:50:10 - Saved numerical results in pickle!
2025-04-01 09:52:37 - ==================================================
2025-04-01 09:52:37 - Running script: convnext.py
2025-04-01 09:52:37 - Script started at: 2025-04-01 09:52:37
2025-04-01 09:52:37 - Using device: cuda
2025-04-01 09:52:37 - CUDA Device Total Memory [GB]:50.936283136
2025-04-01 09:52:37 - Starting new experiment!
2025-04-01 09:52:37 - {
    "model_name": "ConvNeXt-Tiny",
    "pretrained_model": true,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-01 09:52:37 - Training model: (ConvNeXt-Tiny, pretrained=True, finetuning=True, optimizer=Adam)
2025-04-01 09:52:37 - Starting training!
2025-04-01 09:54:37 - Epoch 1/1, Loss: 0.4328, Accuracy: 85.3033%
2025-04-01 09:54:37 - Testing model!
2025-04-01 09:54:53 - Test Accuracy: 87.57%
2025-04-01 09:54:53 - Saved numerical results in pickle!
2025-04-01 09:55:12 - Starting new experiment!
2025-04-01 09:55:12 - {
    "model_name": "ConvNeXt-Tiny",
    "pretrained_model": true,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "SGD",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-01 09:55:13 - Training model: (ConvNeXt-Tiny, pretrained=True, finetuning=True, optimizer=SGD)
2025-04-01 09:55:13 - Starting training!
2025-04-01 09:56:42 - ==================================================
2025-04-01 09:56:42 - Running script: convnext.py
2025-04-01 09:56:42 - Script started at: 2025-04-01 09:56:42
2025-04-01 09:56:42 - Using device: cuda
2025-04-01 09:56:42 - CUDA Device Total Memory [GB]:50.936283136
2025-04-01 09:56:42 - Starting new experiment!
2025-04-01 09:56:42 - {
    "model_name": "ConvNeXt-Tiny",
    "pretrained_model": true,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-01 09:56:43 - Training model: (ConvNeXt-Tiny, pretrained=True, finetuning=True, optimizer=Adam)
2025-04-01 09:56:43 - Starting training!
2025-04-01 09:58:43 - Epoch 1/10, Loss: 0.4331, Accuracy: 85.1150%
2025-04-01 10:00:45 - Epoch 2/10, Loss: 0.3291, Accuracy: 88.3333%
2025-04-01 10:02:47 - Epoch 3/10, Loss: 0.3167, Accuracy: 89.1150%
2025-04-01 10:04:50 - Epoch 4/10, Loss: 0.3090, Accuracy: 89.2600%
2025-04-01 10:06:52 - Epoch 5/10, Loss: 0.3039, Accuracy: 89.5550%
2025-04-01 10:08:55 - Epoch 6/10, Loss: 0.2983, Accuracy: 89.7117%
2025-04-01 10:10:57 - Epoch 7/10, Loss: 0.2951, Accuracy: 89.8550%
2025-04-01 10:12:59 - Epoch 8/10, Loss: 0.2901, Accuracy: 90.0217%
2025-04-01 10:15:01 - Epoch 9/10, Loss: 0.2895, Accuracy: 90.0033%
2025-04-01 10:17:04 - Epoch 10/10, Loss: 0.2876, Accuracy: 90.0900%
2025-04-01 10:17:04 - Testing model!
2025-04-01 10:17:21 - Test Accuracy: 89.55%
2025-04-01 10:17:21 - Saved numerical results in pickle!
2025-04-01 10:17:40 - Starting new experiment!
2025-04-01 10:17:40 - {
    "model_name": "ConvNeXt-Tiny",
    "pretrained_model": true,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "SGD",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-01 10:17:41 - Training model: (ConvNeXt-Tiny, pretrained=True, finetuning=True, optimizer=SGD)
2025-04-01 10:17:41 - Starting training!
2025-04-01 10:19:30 - Epoch 1/10, Loss: 1.4261, Accuracy: 67.1383%
2025-04-01 10:21:18 - Epoch 2/10, Loss: 0.8957, Accuracy: 79.7433%
2025-04-01 10:23:07 - Epoch 3/10, Loss: 0.8010, Accuracy: 81.0117%
2025-04-01 10:24:56 - Epoch 4/10, Loss: 0.7787, Accuracy: 81.3583%
2025-04-01 10:26:44 - Epoch 5/10, Loss: 0.7794, Accuracy: 81.7650%
2025-04-01 10:28:33 - Epoch 6/10, Loss: 0.7966, Accuracy: 81.8950%
2025-04-01 10:30:22 - Epoch 7/10, Loss: 0.8209, Accuracy: 81.9583%
2025-04-01 10:32:10 - Epoch 8/10, Loss: 0.8526, Accuracy: 82.0233%
2025-04-01 10:33:59 - Epoch 9/10, Loss: 0.8880, Accuracy: 81.8817%
2025-04-01 10:35:48 - Epoch 10/10, Loss: 0.9263, Accuracy: 81.8000%
2025-04-01 10:35:48 - Testing model!
2025-04-01 10:36:03 - Test Accuracy: 81.52%
2025-04-01 10:36:03 - Saved numerical results in pickle!
2025-04-01 10:36:20 - Starting new experiment!
2025-04-01 10:36:20 - {
    "model_name": "ConvNeXt-Tiny",
    "pretrained_model": true,
    "finetuning": false,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-01 10:36:20 - Training model: (ConvNeXt-Tiny, pretrained=True, finetuning=False, optimizer=Adam)
2025-04-01 10:36:20 - Starting training!
2025-04-01 10:37:53 - Epoch 1/10, Loss: 0.4318, Accuracy: 85.0983%
2025-04-01 10:39:26 - Epoch 2/10, Loss: 0.3291, Accuracy: 88.2983%
2025-04-01 10:40:59 - Epoch 3/10, Loss: 0.3175, Accuracy: 88.9500%
2025-04-01 10:42:32 - Epoch 4/10, Loss: 0.3083, Accuracy: 89.2950%
2025-04-01 10:44:05 - Epoch 5/10, Loss: 0.3026, Accuracy: 89.6050%
2025-04-01 10:45:38 - Epoch 6/10, Loss: 0.2983, Accuracy: 89.7933%
2025-04-01 10:47:11 - Epoch 7/10, Loss: 0.2933, Accuracy: 89.8183%
2025-04-01 10:48:45 - Epoch 8/10, Loss: 0.2904, Accuracy: 89.9133%
2025-04-01 10:50:18 - Epoch 9/10, Loss: 0.2887, Accuracy: 90.1100%
2025-04-01 10:51:52 - Epoch 10/10, Loss: 0.2886, Accuracy: 90.0100%
2025-04-01 10:51:52 - Testing model!
2025-04-01 10:52:07 - Test Accuracy: 89.59%
2025-04-01 10:52:07 - Saved numerical results in pickle!
2025-04-01 10:52:25 - Starting new experiment!
2025-04-01 10:52:25 - {
    "model_name": "ConvNeXt-Tiny",
    "pretrained_model": true,
    "finetuning": false,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "SGD",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-01 10:52:25 - Training model: (ConvNeXt-Tiny, pretrained=True, finetuning=False, optimizer=SGD)
2025-04-01 10:52:25 - Starting training!
2025-04-01 10:53:58 - Epoch 1/10, Loss: 1.3947, Accuracy: 69.1633%
2025-04-01 10:55:30 - Epoch 2/10, Loss: 0.8894, Accuracy: 79.5133%
2025-04-01 10:57:03 - Epoch 3/10, Loss: 0.7975, Accuracy: 80.8717%
2025-04-01 10:58:37 - Epoch 4/10, Loss: 0.7747, Accuracy: 81.4333%
2025-04-01 11:00:10 - Epoch 5/10, Loss: 0.7780, Accuracy: 81.6500%
2025-04-01 11:01:44 - Epoch 6/10, Loss: 0.7949, Accuracy: 81.8500%
2025-04-01 11:03:17 - Epoch 7/10, Loss: 0.8203, Accuracy: 81.9667%
2025-04-01 11:04:50 - Epoch 8/10, Loss: 0.8521, Accuracy: 82.0000%
2025-04-01 11:06:23 - Epoch 9/10, Loss: 0.8867, Accuracy: 81.8383%
2025-04-01 11:07:57 - Epoch 10/10, Loss: 0.9251, Accuracy: 81.9167%
2025-04-01 11:07:57 - Testing model!
2025-04-01 11:08:12 - Test Accuracy: 81.70%
2025-04-01 11:08:12 - Saved numerical results in pickle!
2025-04-01 11:08:29 - Starting new experiment!
2025-04-01 11:08:29 - {
    "model_name": "ConvNeXt-Tiny",
    "pretrained_model": false,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-01 11:08:30 - Training model: (ConvNeXt-Tiny, pretrained=False, finetuning=True, optimizer=Adam)
2025-04-01 11:08:30 - Starting training!
2025-04-01 11:10:15 - Epoch 1/10, Loss: 1.9657, Accuracy: 29.0900%
2025-04-01 11:12:00 - Epoch 2/10, Loss: 1.8563, Accuracy: 34.5617%
2025-04-01 11:13:46 - Epoch 3/10, Loss: 1.8089, Accuracy: 37.3283%
2025-04-01 11:15:31 - Epoch 4/10, Loss: 1.7812, Accuracy: 38.7317%
2025-04-01 11:17:17 - Epoch 5/10, Loss: 1.7590, Accuracy: 39.4983%
2025-04-01 11:19:02 - Epoch 6/10, Loss: 1.7450, Accuracy: 40.3350%
2025-04-01 11:20:47 - Epoch 7/10, Loss: 1.7331, Accuracy: 41.0050%
2025-04-01 11:22:33 - Epoch 8/10, Loss: 1.7239, Accuracy: 41.6983%
2025-04-01 11:24:18 - Epoch 9/10, Loss: 1.7172, Accuracy: 42.1850%
2025-04-01 11:26:04 - Epoch 10/10, Loss: 1.7099, Accuracy: 42.3783%
2025-04-01 11:26:04 - Testing model!
2025-04-01 11:26:19 - Test Accuracy: 41.84%
2025-04-01 11:26:19 - Saved numerical results in pickle!
2025-04-01 11:26:37 - Starting new experiment!
2025-04-01 11:26:37 - {
    "model_name": "ConvNeXt-Tiny",
    "pretrained_model": false,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "SGD",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-01 11:26:37 - Training model: (ConvNeXt-Tiny, pretrained=False, finetuning=True, optimizer=SGD)
2025-04-01 11:26:37 - Starting training!
2025-04-01 11:28:29 - Epoch 1/10, Loss: 2.1057, Accuracy: 23.1200%
2025-04-01 11:30:21 - Epoch 2/10, Loss: 2.0471, Accuracy: 27.8667%
2025-04-01 11:32:13 - Epoch 3/10, Loss: 2.0328, Accuracy: 29.5700%
2025-04-01 11:34:05 - Epoch 4/10, Loss: 2.0258, Accuracy: 30.3750%
2025-04-01 11:35:57 - Epoch 5/10, Loss: 2.0225, Accuracy: 30.5217%
2025-04-01 11:37:49 - Epoch 6/10, Loss: 2.0217, Accuracy: 31.1683%
2025-04-01 11:39:42 - Epoch 7/10, Loss: 2.0228, Accuracy: 31.4350%
2025-04-01 11:41:35 - Epoch 8/10, Loss: 2.0250, Accuracy: 31.6683%
2025-04-01 11:43:26 - Epoch 9/10, Loss: 2.0277, Accuracy: 31.4550%
2025-04-01 11:45:22 - Epoch 10/10, Loss: 2.0314, Accuracy: 31.2017%
2025-04-01 11:45:22 - Testing model!
2025-04-01 11:45:38 - Test Accuracy: 27.36%
2025-04-01 11:45:38 - Saved numerical results in pickle!
2025-04-01 11:45:56 - Starting new experiment!
2025-04-01 11:45:56 - {
    "model_name": "ConvNeXt-Tiny",
    "pretrained_model": false,
    "finetuning": false,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-01 11:45:56 - Training model: (ConvNeXt-Tiny, pretrained=False, finetuning=False, optimizer=Adam)
2025-04-01 11:45:56 - Starting training!
2025-04-01 11:47:33 - Epoch 1/10, Loss: 1.9661, Accuracy: 28.7900%
2025-04-01 11:49:09 - Epoch 2/10, Loss: 1.8457, Accuracy: 35.5650%
2025-04-01 11:50:46 - Epoch 3/10, Loss: 1.8003, Accuracy: 37.8817%
2025-04-01 11:52:31 - Epoch 4/10, Loss: 1.7708, Accuracy: 39.4767%
2025-04-01 11:54:14 - Epoch 5/10, Loss: 1.7500, Accuracy: 40.2567%
2025-04-01 11:55:53 - Epoch 6/10, Loss: 1.7335, Accuracy: 41.1067%
2025-04-01 11:57:30 - Epoch 7/10, Loss: 1.7208, Accuracy: 41.8983%
2025-04-01 11:59:07 - Epoch 8/10, Loss: 1.7107, Accuracy: 42.1733%
2025-04-01 12:00:43 - Epoch 9/10, Loss: 1.7019, Accuracy: 42.8467%
2025-04-01 12:02:20 - Epoch 10/10, Loss: 1.6966, Accuracy: 42.7600%
2025-04-01 12:02:20 - Testing model!
2025-04-01 12:02:36 - Test Accuracy: 40.80%
2025-04-01 12:02:36 - Saved numerical results in pickle!
2025-04-01 12:02:54 - Starting new experiment!
2025-04-01 12:02:54 - {
    "model_name": "ConvNeXt-Tiny",
    "pretrained_model": false,
    "finetuning": false,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "SGD",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-01 12:02:54 - Training model: (ConvNeXt-Tiny, pretrained=False, finetuning=False, optimizer=SGD)
2025-04-01 12:02:54 - Starting training!
2025-04-01 12:04:27 - Epoch 1/10, Loss: 2.0870, Accuracy: 24.8250%
2025-04-01 12:06:01 - Epoch 2/10, Loss: 2.0364, Accuracy: 29.3667%
2025-04-01 12:07:35 - Epoch 3/10, Loss: 2.0224, Accuracy: 30.5667%
2025-04-01 12:09:12 - Epoch 4/10, Loss: 2.0160, Accuracy: 31.0450%
2025-04-01 12:10:49 - Epoch 5/10, Loss: 2.0131, Accuracy: 31.7600%
2025-04-01 12:12:31 - Epoch 6/10, Loss: 2.0128, Accuracy: 32.0167%
2025-04-01 12:14:07 - Epoch 7/10, Loss: 2.0140, Accuracy: 32.2633%
2025-04-01 12:15:47 - Epoch 8/10, Loss: 2.0163, Accuracy: 32.3367%
2025-04-01 12:17:27 - Epoch 9/10, Loss: 2.0196, Accuracy: 32.1017%
2025-04-01 12:19:01 - Epoch 10/10, Loss: 2.0234, Accuracy: 32.1100%
2025-04-01 12:19:01 - Testing model!
2025-04-01 12:19:17 - Test Accuracy: 33.95%
2025-04-01 12:19:17 - Saved numerical results in pickle!
2025-04-01 12:19:36 - Starting new experiment!
2025-04-01 12:19:36 - {
    "model_name": "ConvNeXt-Base",
    "pretrained_model": true,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-01 12:19:42 - Training model: (ConvNeXt-Base, pretrained=True, finetuning=True, optimizer=Adam)
2025-04-01 12:19:42 - Starting training!
2025-04-01 12:23:11 - Epoch 1/10, Loss: 0.4264, Accuracy: 85.3867%
2025-04-01 12:26:40 - Epoch 2/10, Loss: 0.3316, Accuracy: 88.3867%
2025-04-01 12:30:12 - Epoch 3/10, Loss: 0.3179, Accuracy: 88.8700%
2025-04-01 12:33:47 - Epoch 4/10, Loss: 0.3126, Accuracy: 89.1483%
2025-04-01 12:37:20 - Epoch 5/10, Loss: 0.3045, Accuracy: 89.3217%
2025-04-01 12:40:53 - Epoch 6/10, Loss: 0.3021, Accuracy: 89.5067%
2025-04-01 12:44:27 - Epoch 7/10, Loss: 0.2977, Accuracy: 89.6750%
2025-04-01 12:47:56 - Epoch 8/10, Loss: 0.2973, Accuracy: 89.7700%
2025-04-01 12:51:26 - Epoch 9/10, Loss: 0.2965, Accuracy: 89.8317%
2025-04-01 12:55:00 - Epoch 10/10, Loss: 0.2966, Accuracy: 89.7483%
2025-04-01 12:55:00 - Testing model!
2025-04-01 12:55:30 - Test Accuracy: 90.18%
2025-04-01 12:55:30 - Saved numerical results in pickle!
2025-04-01 12:56:02 - Starting new experiment!
2025-04-01 12:56:02 - {
    "model_name": "ConvNeXt-Base",
    "pretrained_model": true,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "SGD",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-01 12:56:03 - Training model: (ConvNeXt-Base, pretrained=True, finetuning=True, optimizer=SGD)
2025-04-01 12:56:03 - Starting training!
2025-04-01 12:59:33 - Epoch 1/10, Loss: 1.5825, Accuracy: 65.0667%
2025-04-01 13:03:01 - Epoch 2/10, Loss: 1.0395, Accuracy: 79.5900%
2025-04-01 13:06:29 - Epoch 3/10, Loss: 0.9128, Accuracy: 80.7267%
2025-04-01 13:09:57 - Epoch 4/10, Loss: 0.8774, Accuracy: 81.4200%
2025-04-01 13:13:25 - Epoch 5/10, Loss: 0.8755, Accuracy: 81.5333%
2025-04-01 13:16:53 - Epoch 6/10, Loss: 0.8894, Accuracy: 81.6583%
2025-04-01 13:20:21 - Epoch 7/10, Loss: 0.9132, Accuracy: 81.7850%
2025-04-01 13:23:49 - Epoch 8/10, Loss: 0.9458, Accuracy: 81.7167%
2025-04-01 13:27:17 - Epoch 9/10, Loss: 0.9808, Accuracy: 81.6650%
2025-04-01 13:30:45 - Epoch 10/10, Loss: 1.0207, Accuracy: 81.3950%
2025-04-01 13:30:45 - Testing model!
2025-04-01 13:31:15 - Test Accuracy: 81.72%
2025-04-01 13:31:15 - Saved numerical results in pickle!
2025-04-01 13:31:48 - Starting new experiment!
2025-04-01 13:31:48 - {
    "model_name": "ConvNeXt-Base",
    "pretrained_model": true,
    "finetuning": false,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-01 13:31:49 - Training model: (ConvNeXt-Base, pretrained=True, finetuning=False, optimizer=Adam)
2025-04-01 13:31:49 - Starting training!
2025-04-01 13:34:56 - Epoch 1/10, Loss: 0.4253, Accuracy: 85.4733%
2025-04-01 13:38:04 - Epoch 2/10, Loss: 0.3302, Accuracy: 88.3067%
2025-04-01 13:41:11 - Epoch 3/10, Loss: 0.3167, Accuracy: 88.8633%
2025-04-01 13:44:18 - Epoch 4/10, Loss: 0.3067, Accuracy: 89.4317%
2025-04-01 13:47:26 - Epoch 5/10, Loss: 0.3035, Accuracy: 89.3567%
2025-04-01 13:50:33 - Epoch 6/10, Loss: 0.2993, Accuracy: 89.5717%
2025-04-01 13:53:41 - Epoch 7/10, Loss: 0.2973, Accuracy: 89.7483%
2025-04-01 13:56:48 - Epoch 8/10, Loss: 0.2967, Accuracy: 89.7850%
2025-04-01 13:59:56 - Epoch 9/10, Loss: 0.2955, Accuracy: 89.9100%
2025-04-01 14:03:03 - Epoch 10/10, Loss: 0.2948, Accuracy: 89.8417%
2025-04-01 14:03:04 - Testing model!
2025-04-01 14:03:34 - Test Accuracy: 90.15%
2025-04-01 14:03:34 - Saved numerical results in pickle!
2025-04-01 14:04:07 - Starting new experiment!
2025-04-01 14:04:07 - {
    "model_name": "ConvNeXt-Base",
    "pretrained_model": true,
    "finetuning": false,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "SGD",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-01 14:04:08 - Training model: (ConvNeXt-Base, pretrained=True, finetuning=False, optimizer=SGD)
2025-04-01 14:04:08 - Starting training!
2025-04-01 14:07:15 - Epoch 1/10, Loss: 1.5338, Accuracy: 68.3633%
2025-04-01 14:10:22 - Epoch 2/10, Loss: 1.0287, Accuracy: 79.1567%
2025-04-01 14:13:30 - Epoch 3/10, Loss: 0.9102, Accuracy: 80.5250%
2025-04-01 14:16:37 - Epoch 4/10, Loss: 0.8764, Accuracy: 81.0833%
2025-04-01 14:19:45 - Epoch 5/10, Loss: 0.8752, Accuracy: 81.4400%
2025-04-01 14:22:52 - Epoch 6/10, Loss: 0.8888, Accuracy: 81.5833%
2025-04-01 14:26:00 - Epoch 7/10, Loss: 0.9140, Accuracy: 81.6750%
2025-04-01 14:29:07 - Epoch 8/10, Loss: 0.9453, Accuracy: 81.6033%
2025-04-01 14:32:14 - Epoch 9/10, Loss: 0.9808, Accuracy: 81.5683%
2025-04-01 14:35:21 - Epoch 10/10, Loss: 1.0192, Accuracy: 81.4700%
2025-04-01 14:35:22 - Testing model!
2025-04-01 14:35:52 - Test Accuracy: 81.72%
2025-04-01 14:35:52 - Saved numerical results in pickle!
2025-04-01 14:36:25 - Starting new experiment!
2025-04-01 14:36:25 - {
    "model_name": "ConvNeXt-Base",
    "pretrained_model": false,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-01 14:36:26 - Training model: (ConvNeXt-Base, pretrained=False, finetuning=True, optimizer=Adam)
2025-04-01 14:36:26 - Starting training!
2025-04-01 14:39:58 - Epoch 1/10, Loss: 1.9950, Accuracy: 27.4683%
2025-04-01 14:43:31 - Epoch 2/10, Loss: 1.8674, Accuracy: 33.9533%
2025-04-01 14:47:03 - Epoch 3/10, Loss: 1.8157, Accuracy: 36.9200%
2025-04-01 14:50:36 - Epoch 4/10, Loss: 1.7822, Accuracy: 38.2033%
2025-04-01 14:54:09 - Epoch 5/10, Loss: 1.7592, Accuracy: 39.6083%
2025-04-01 14:57:42 - Epoch 6/10, Loss: 1.7423, Accuracy: 40.4533%
2025-04-01 15:01:14 - Epoch 7/10, Loss: 1.7290, Accuracy: 41.1967%
2025-04-01 15:04:47 - Epoch 8/10, Loss: 1.7165, Accuracy: 42.0833%
2025-04-01 15:08:19 - Epoch 9/10, Loss: 1.7062, Accuracy: 42.0917%
2025-04-01 15:11:52 - Epoch 10/10, Loss: 1.6980, Accuracy: 42.7633%
2025-04-01 15:11:52 - Testing model!
2025-04-01 15:12:22 - Test Accuracy: 44.61%
2025-04-01 15:12:22 - Saved numerical results in pickle!
2025-04-01 15:12:55 - Starting new experiment!
2025-04-01 15:12:55 - {
    "model_name": "ConvNeXt-Base",
    "pretrained_model": false,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "SGD",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-01 15:12:55 - Training model: (ConvNeXt-Base, pretrained=False, finetuning=True, optimizer=SGD)
2025-04-01 15:12:55 - Starting training!
2025-04-01 15:16:28 - Epoch 1/10, Loss: 2.0831, Accuracy: 24.8433%
2025-04-01 15:20:00 - Epoch 2/10, Loss: 2.0311, Accuracy: 28.9500%
2025-04-01 15:23:32 - Epoch 3/10, Loss: 2.0160, Accuracy: 30.6117%
2025-04-01 15:27:04 - Epoch 4/10, Loss: 2.0087, Accuracy: 31.2533%
2025-04-01 15:30:36 - Epoch 5/10, Loss: 2.0050, Accuracy: 31.8867%
2025-04-01 15:34:09 - Epoch 6/10, Loss: 2.0042, Accuracy: 32.1867%
2025-04-01 15:37:41 - Epoch 7/10, Loss: 2.0048, Accuracy: 32.3950%
2025-04-01 15:41:13 - Epoch 8/10, Loss: 2.0067, Accuracy: 32.1750%
2025-04-01 15:44:45 - Epoch 9/10, Loss: 2.0098, Accuracy: 32.6983%
2025-04-01 15:48:18 - Epoch 10/10, Loss: 2.0136, Accuracy: 32.5117%
2025-04-01 15:48:18 - Testing model!
2025-04-01 15:48:48 - Test Accuracy: 33.82%
2025-04-01 15:48:48 - Saved numerical results in pickle!
2025-04-01 15:49:21 - Starting new experiment!
2025-04-01 15:49:21 - {
    "model_name": "ConvNeXt-Base",
    "pretrained_model": false,
    "finetuning": false,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-01 15:49:21 - Training model: (ConvNeXt-Base, pretrained=False, finetuning=False, optimizer=Adam)
2025-04-01 15:49:21 - Starting training!
2025-04-01 15:52:29 - Epoch 1/10, Loss: 1.9884, Accuracy: 28.2750%
2025-04-01 15:55:37 - Epoch 2/10, Loss: 1.8606, Accuracy: 34.4517%
2025-04-01 15:58:44 - Epoch 3/10, Loss: 1.8027, Accuracy: 37.4900%
2025-04-01 16:01:52 - Epoch 4/10, Loss: 1.7707, Accuracy: 39.0433%
2025-04-01 16:04:59 - Epoch 5/10, Loss: 1.7479, Accuracy: 40.2233%
2025-04-01 16:08:13 - Epoch 6/10, Loss: 1.7312, Accuracy: 41.0650%
2025-04-01 16:11:25 - Epoch 7/10, Loss: 1.7182, Accuracy: 41.7567%
2025-04-01 16:14:32 - Epoch 8/10, Loss: 1.7064, Accuracy: 42.4233%
2025-04-01 16:17:41 - Epoch 9/10, Loss: 1.6950, Accuracy: 42.8850%
2025-04-01 16:20:49 - Epoch 10/10, Loss: 1.6877, Accuracy: 43.1233%
2025-04-01 16:20:50 - Testing model!
2025-04-01 16:21:20 - Test Accuracy: 43.42%
2025-04-01 16:21:20 - Saved numerical results in pickle!
2025-04-01 16:21:53 - Starting new experiment!
2025-04-01 16:21:53 - {
    "model_name": "ConvNeXt-Base",
    "pretrained_model": false,
    "finetuning": false,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "SGD",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-01 16:21:54 - Training model: (ConvNeXt-Base, pretrained=False, finetuning=False, optimizer=SGD)
2025-04-01 16:21:54 - Starting training!
2025-04-01 16:25:01 - Epoch 1/10, Loss: 2.0891, Accuracy: 24.6967%
2025-04-01 16:28:08 - Epoch 2/10, Loss: 2.0324, Accuracy: 29.8683%
2025-04-01 16:31:15 - Epoch 3/10, Loss: 2.0182, Accuracy: 30.7950%
2025-04-01 16:34:22 - Epoch 4/10, Loss: 2.0113, Accuracy: 31.4367%
2025-04-01 16:37:29 - Epoch 5/10, Loss: 2.0083, Accuracy: 31.8367%
2025-04-01 16:40:36 - Epoch 6/10, Loss: 2.0075, Accuracy: 32.5883%
2025-04-01 16:43:45 - Epoch 7/10, Loss: 2.0082, Accuracy: 32.2367%
2025-04-01 16:46:55 - Epoch 8/10, Loss: 2.0104, Accuracy: 32.4567%
2025-04-01 16:50:02 - Epoch 9/10, Loss: 2.0133, Accuracy: 32.3617%
2025-04-01 16:53:11 - Epoch 10/10, Loss: 2.0171, Accuracy: 32.4517%
2025-04-01 16:53:11 - Testing model!
2025-04-01 16:53:41 - Test Accuracy: 32.44%
2025-04-01 16:53:41 - Saved numerical results in pickle!
2025-04-01 16:54:15 - Saved numerical results in pickle!
2025-04-01 16:54:15 - Script ended at: 2025-04-01 16:54:15
2025-04-01 16:54:15 - Total execution time: 25052.85 seconds
2025-04-01 16:54:15 - ==================================================
