2025-03-10 20:54:53 - ==================================================
2025-03-10 20:54:53 - Running script: pretrained_models.py
2025-03-10 20:54:53 - Script started at: 2025-03-10 20:54:53
2025-03-10 20:54:53 - Using device: cuda
2025-03-10 20:54:53 - CUDA Device Total Memory [GB]:25.380061184
2025-03-10 20:54:53 - Hyperparameters:
2025-03-10 20:54:53 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-10 20:54:54 - Training model: (ResNet50, pre-trained=False)
2025-03-10 20:59:38 - Epoch 1/1, Loss: 2.3883
2025-03-10 20:59:58 - Test Accuracy: 26.74%
2025-03-10 21:01:09 - ==================================================
2025-03-10 21:01:09 - Running script: pretrained_models.py
2025-03-10 21:01:09 - Script started at: 2025-03-10 21:01:09
2025-03-10 21:01:09 - Using device: cuda
2025-03-10 21:01:09 - CUDA Device Total Memory [GB]:25.380061184
2025-03-10 21:01:09 - Hyperparameters:
2025-03-10 21:01:09 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-10 21:01:10 - Training model: (ResNet50, pretrained=False)
2025-03-10 21:05:55 - Epoch 1/10, Loss: 2.4402
2025-03-10 21:10:41 - Epoch 2/10, Loss: 1.9884
2025-03-10 21:15:26 - Epoch 3/10, Loss: 1.8016
2025-03-10 21:20:12 - Epoch 4/10, Loss: 1.7034
2025-03-10 21:24:58 - Epoch 5/10, Loss: 1.6270
2025-03-10 21:29:42 - Epoch 6/10, Loss: 1.5667
2025-03-10 21:34:28 - Epoch 7/10, Loss: 1.5174
2025-03-10 21:39:13 - Epoch 8/10, Loss: 1.4832
2025-03-10 21:43:58 - Epoch 9/10, Loss: 1.4626
2025-03-10 21:48:43 - Epoch 10/10, Loss: 1.4347
2025-03-10 21:49:04 - Test Accuracy: 45.98%
2025-03-10 21:49:04 - Hyperparameters:
2025-03-10 21:49:04 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-10 21:49:04 - Training model: (ResNet50, pretrained=True)
2025-03-10 21:50:58 - Epoch 1/10, Loss: 0.7007
2025-03-10 21:52:52 - Epoch 2/10, Loss: 0.5286
2025-03-10 21:54:47 - Epoch 3/10, Loss: 0.5006
2025-03-10 21:56:41 - Epoch 4/10, Loss: 0.4831
2025-03-10 21:58:35 - Epoch 5/10, Loss: 0.4768
2025-03-10 22:00:29 - Epoch 6/10, Loss: 0.4714
2025-03-10 22:02:24 - Epoch 7/10, Loss: 0.4673
2025-03-10 22:04:18 - Epoch 8/10, Loss: 0.4630
2025-03-10 22:06:12 - Epoch 9/10, Loss: 0.4605
2025-03-10 22:08:07 - Epoch 10/10, Loss: 0.4566
2025-03-10 22:08:25 - Test Accuracy: 84.87%
2025-03-10 22:08:25 - Script ended at: 2025-03-10 22:08:25
2025-03-10 22:08:25 - Total execution time: 4035.52 seconds
2025-03-10 22:08:25 - ==================================================
2025-03-11 06:41:58 - ==================================================
2025-03-11 06:41:58 - Running script: pretrained_models.py
2025-03-11 06:41:58 - Script started at: 2025-03-11 06:41:58
2025-03-11 06:41:58 - Using device: cuda
2025-03-11 06:41:58 - CUDA Device Total Memory [GB]:25.380061184
2025-03-11 06:41:58 - Starting new experiment!
2025-03-11 06:41:58 - Hyperparameters:
2025-03-11 06:41:58 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-11 06:41:58 - Training model: (ResNet50, pretrained=True)
2025-03-11 06:44:08 - Epoch 1/10, Loss: 0.7119, Accuracy: 0.7539
2025-03-11 06:44:56 - ==================================================
2025-03-11 06:44:56 - Running script: pretrained_models.py
2025-03-11 06:44:56 - Script started at: 2025-03-11 06:44:56
2025-03-11 06:44:56 - Using device: cuda
2025-03-11 06:44:56 - CUDA Device Total Memory [GB]:25.380061184
2025-03-11 06:44:56 - Starting new experiment!
2025-03-11 06:44:56 - Hyperparameters:
2025-03-11 06:44:56 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-11 06:44:57 - Training model: (ResNet50, pretrained=True)
2025-03-11 06:47:05 - Epoch 1/1, Loss: 0.7145, Accuracy: 0.7532
2025-03-11 06:47:25 - Test Accuracy: 80.55%
2025-03-11 06:47:25 - Script ended at: 2025-03-11 06:47:25
2025-03-11 06:47:25 - Total execution time: 148.31 seconds
2025-03-11 06:47:25 - ==================================================
2025-03-11 06:47:53 - ==================================================
2025-03-11 06:47:53 - Running script: pretrained_models.py
2025-03-11 06:47:53 - Script started at: 2025-03-11 06:47:53
2025-03-11 06:47:53 - Using device: cuda
2025-03-11 06:47:53 - CUDA Device Total Memory [GB]:25.380061184
2025-03-11 06:47:54 - Starting new experiment!
2025-03-11 06:47:54 - Hyperparameters:
2025-03-11 06:47:54 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-11 06:47:54 - Training model: (ResNet50, pretrained=True)
2025-03-11 06:50:03 - Epoch 1/1, Loss: 0.7073, Accuracy: 0.7567
2025-03-11 06:50:22 - Test Accuracy: 79.46%
2025-03-11 06:50:22 - Script ended at: 2025-03-11 06:50:22
2025-03-11 06:50:22 - Total execution time: 148.87 seconds
2025-03-11 06:50:22 - ==================================================
2025-03-11 06:52:36 - ==================================================
2025-03-11 06:52:36 - Running script: pretrained_models.py
2025-03-11 06:52:36 - Script started at: 2025-03-11 06:52:36
2025-03-11 06:52:36 - Using device: cuda
2025-03-11 06:52:36 - CUDA Device Total Memory [GB]:25.380061184
2025-03-11 06:52:36 - Starting new experiment!
2025-03-11 06:52:36 - Hyperparameters:
2025-03-11 06:52:36 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-11 06:52:36 - Training model: (ResNet50, pretrained=True)
2025-03-11 06:54:45 - Epoch 1/1, Loss: 0.7140, Accuracy: 0.7552
2025-03-11 06:55:05 - Test Accuracy: 80.30%
2025-03-11 06:55:25 - Script ended at: 2025-03-11 06:55:25
2025-03-11 06:55:25 - Total execution time: 169.02 seconds
2025-03-11 06:55:25 - ==================================================
2025-03-11 08:49:16 - ==================================================
2025-03-11 08:49:16 - Running script: pretrained_models.py
2025-03-11 08:49:16 - Script started at: 2025-03-11 08:49:16
2025-03-11 08:49:16 - Using device: cuda
2025-03-11 08:49:16 - CUDA Device Total Memory [GB]:25.380061184
2025-03-11 08:49:16 - Starting new experiment!
2025-03-11 08:49:16 - Hyperparameters:
2025-03-11 08:49:16 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-11 08:49:17 - Training model: (ResNet50, pretrained=False)
2025-03-11 08:54:02 - Epoch 1/1, Loss: 2.4798, Accuracy: 0.1989
2025-03-11 08:54:21 - Test Accuracy: 35.11%
2025-03-11 08:55:16 - ==================================================
2025-03-11 08:55:16 - Running script: pretrained_models.py
2025-03-11 08:55:16 - Script started at: 2025-03-11 08:55:16
2025-03-11 08:55:16 - Using device: cuda
2025-03-11 08:55:16 - CUDA Device Total Memory [GB]:25.380061184
2025-03-11 08:55:16 - Starting new experiment!
2025-03-11 08:55:16 - Hyperparameters:
2025-03-11 08:55:16 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-11 08:55:17 - Training model: (ResNet50, pretrained=False)
2025-03-11 09:00:02 - Epoch 1/1, Loss: 2.4587, Accuracy: 0.2043
2025-03-11 09:00:21 - Test Accuracy: 19.82%
2025-03-11 09:05:03 - ==================================================
2025-03-11 09:05:03 - Running script: pretrained_models.py
2025-03-11 09:05:03 - Script started at: 2025-03-11 09:05:03
2025-03-11 09:05:03 - Using device: cuda
2025-03-11 09:05:03 - CUDA Device Total Memory [GB]:25.380061184
2025-03-11 09:05:03 - Starting new experiment!
2025-03-11 09:05:03 - Hyperparameters:
2025-03-11 09:05:03 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-11 09:05:04 - Training model: (ResNet50, pretrained=False)
2025-03-11 09:09:48 - Epoch 1/1, Loss: 2.4316, Accuracy: 21.4300%
2025-03-11 09:10:07 - Test Accuracy: 29.45%
2025-03-11 09:10:26 - Starting new experiment!
2025-03-11 09:10:26 - Hyperparameters:
2025-03-11 09:14:49 - ==================================================
2025-03-11 09:14:49 - Running script: pretrained_models.py
2025-03-11 09:14:49 - Script started at: 2025-03-11 09:14:49
2025-03-11 09:14:49 - Using device: cuda
2025-03-11 09:14:49 - CUDA Device Total Memory [GB]:25.380061184
2025-03-11 09:14:49 - Starting new experiment!
2025-03-11 09:14:49 - Hyperparameters:
2025-03-11 09:14:49 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-11 09:14:49 - Training model: (ResNet50, pretrained=False)
2025-03-11 09:19:33 - Epoch 1/1, Loss: 2.4628, Accuracy: 20.2367%
2025-03-11 09:19:53 - Test Accuracy: 19.21%
2025-03-11 09:20:12 - Starting new experiment!
2025-03-11 09:20:12 - Hyperparameters:
2025-03-11 09:32:13 - ==================================================
2025-03-11 09:32:13 - Running script: pretrained_models.py
2025-03-11 09:32:13 - Script started at: 2025-03-11 09:32:13
2025-03-11 09:32:13 - Using device: cuda
2025-03-11 09:32:13 - CUDA Device Total Memory [GB]:25.380061184
2025-03-11 09:32:13 - Starting new experiment!
2025-03-11 09:32:13 - Hyperparameters:
2025-03-11 09:32:13 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-11 09:32:13 - Training model: (ResNet50, pretrained=False)
2025-03-11 09:36:58 - Epoch 1/1, Loss: 2.4541, Accuracy: 20.6283%
2025-03-11 09:37:18 - Test Accuracy: 37.67%
2025-03-11 09:43:31 - ==================================================
2025-03-11 09:43:31 - Running script: pretrained_models.py
2025-03-11 09:43:31 - Script started at: 2025-03-11 09:43:31
2025-03-11 09:43:31 - Using device: cuda
2025-03-11 09:43:31 - CUDA Device Total Memory [GB]:25.380061184
2025-03-11 09:43:31 - Starting new experiment!
2025-03-11 09:43:31 - Hyperparameters:
2025-03-11 09:43:31 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-11 09:43:32 - Training model: (ResNet50, pretrained=False)
2025-03-11 09:48:16 - Epoch 1/1, Loss: 2.4595, Accuracy: 20.9567%
2025-03-11 09:48:35 - Test Accuracy: 23.08%
2025-03-11 09:55:30 - ==================================================
2025-03-11 09:55:30 - Running script: pretrained_models.py
2025-03-11 09:55:30 - Script started at: 2025-03-11 09:55:30
2025-03-11 09:55:30 - Using device: cuda
2025-03-11 09:55:30 - CUDA Device Total Memory [GB]:25.380061184
2025-03-11 09:55:30 - Starting new experiment!
2025-03-11 09:55:30 - Hyperparameters:
2025-03-11 09:55:30 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-11 09:55:30 - Training model: (ResNet50, pretrained=False)
2025-03-11 10:00:14 - Epoch 1/1, Loss: 2.4272, Accuracy: 20.6900%
2025-03-11 10:00:33 - Test Accuracy: 28.40%
2025-03-11 10:00:53 - Starting new experiment!
2025-03-11 10:00:53 - Hyperparameters:
2025-03-11 10:34:38 - ==================================================
2025-03-11 10:34:38 - Running script: pretrained_models.py
2025-03-11 10:34:38 - Script started at: 2025-03-11 10:34:38
2025-03-11 10:34:38 - Using device: cuda
2025-03-11 10:34:38 - CUDA Device Total Memory [GB]:25.380061184
2025-03-11 10:34:38 - Starting new experiment!
2025-03-11 10:34:38 - Hyperparameters:
2025-03-11 10:34:38 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-11 10:34:39 - Training model: (ResNet50, pretrained=False)
2025-03-11 10:39:22 - Epoch 1/1, Loss: 2.4305, Accuracy: 21.4833%
2025-03-11 10:39:42 - Test Accuracy: 24.57%
2025-03-11 10:40:02 - Starting new experiment!
2025-03-11 10:40:02 - Hyperparameters:
2025-03-11 10:53:01 - ==================================================
2025-03-11 10:53:01 - Running script: pretrained_models.py
2025-03-11 10:53:01 - Script started at: 2025-03-11 10:53:01
2025-03-11 10:53:01 - Using device: cuda
2025-03-11 10:53:01 - CUDA Device Total Memory [GB]:25.380061184
2025-03-11 10:53:01 - Starting new experiment!
2025-03-11 10:53:01 - Hyperparameters:
2025-03-11 10:53:01 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-11 10:53:01 - Training model: (ResNet50, pretrained=False)
2025-03-11 10:57:51 - Epoch 1/1, Loss: 2.4094, Accuracy: 22.0433%
2025-03-11 10:58:10 - Test Accuracy: 30.25%
2025-03-11 10:58:31 - Starting new experiment!
2025-03-11 10:58:31 - Hyperparameters:
2025-03-11 10:58:31 - {
    "model_name": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=2048, out_features=10, bias=True)\n)",
    "pretrained_model": true,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-11 11:48:16 - ==================================================
2025-03-11 11:48:16 - Running script: pretrained_models.py
2025-03-11 11:48:16 - Script started at: 2025-03-11 11:48:16
2025-03-11 11:48:16 - Using device: cuda
2025-03-11 11:48:16 - CUDA Device Total Memory [GB]:25.380061184
2025-03-11 11:48:16 - Starting new experiment!
2025-03-11 11:48:16 - Hyperparameters:
2025-03-11 11:48:16 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-11 11:48:17 - Training model: (ResNet50, pretrained=False)
2025-03-11 11:52:43 - Epoch 1/1, Loss: 2.3832, Accuracy: 22.3200%
2025-03-11 11:53:00 - Test Accuracy: 30.99%
2025-03-11 11:53:19 - Starting new experiment!
2025-03-11 11:53:19 - Hyperparameters:
2025-03-11 11:53:19 - {
    "model_name": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=2048, out_features=10, bias=True)\n)",
    "pretrained_model": true,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-11 15:50:20 - ==================================================
2025-03-11 15:50:20 - Running script: pretrained_models.py
2025-03-11 15:50:20 - Script started at: 2025-03-11 15:50:20
2025-03-11 15:50:20 - Using device: cuda
2025-03-11 15:50:20 - CUDA Device Total Memory [GB]:25.38635264
2025-03-11 15:50:21 - Starting new experiment!
2025-03-11 15:50:21 - Hyperparameters:
2025-03-11 15:50:21 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-11 15:50:21 - Training model: (ResNet50, pretrained=False)
2025-03-11 15:51:44 - Epoch 1/1, Loss: 2.4490, Accuracy: 20.4517%
2025-03-11 15:51:56 - Test Accuracy: 21.06%
2025-03-11 15:52:08 - Starting new experiment!
2025-03-11 15:52:08 - Hyperparameters:
2025-03-11 15:52:08 - {
    "model_name": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=2048, out_features=10, bias=True)\n)",
    "pretrained_model": true,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-11 16:07:25 - ==================================================
2025-03-11 16:07:25 - Running script: pretrained_models.py
2025-03-11 16:07:25 - Script started at: 2025-03-11 16:07:25
2025-03-11 16:07:25 - Using device: cuda
2025-03-11 16:07:25 - CUDA Device Total Memory [GB]:25.38635264
2025-03-11 16:07:25 - Starting new experiment!
2025-03-11 16:07:25 - Hyperparameters:
2025-03-11 16:07:25 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-11 16:07:25 - Training model: (ResNet50, pretrained=False)
2025-03-11 16:08:47 - Epoch 1/1, Loss: 2.4267, Accuracy: 21.0000%
2025-03-11 16:09:01 - Test Accuracy: 31.56%
2025-03-11 16:09:13 - Starting new experiment!
2025-03-11 16:09:13 - Hyperparameters:
2025-03-11 16:09:13 - {
    "model_name": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=2048, out_features=10, bias=True)\n)",
    "pretrained_model": true,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-15 11:37:40 - ==================================================
2025-03-15 11:37:40 - Running script: pretrained_models.py
2025-03-15 11:37:40 - Script started at: 2025-03-15 11:37:40
2025-03-15 11:37:40 - Using device: cuda
2025-03-15 11:37:40 - CUDA Device Total Memory [GB]:50.936283136
2025-03-15 11:37:51 - Starting new experiment!
2025-03-15 11:37:51 - Hyperparameters:
2025-03-15 11:37:51 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-15 11:37:52 - Training model: (ResNet50, pretrained=False)
2025-03-15 11:39:25 - Epoch 1/1, Loss: 2.4391, Accuracy: 20.9217%
2025-03-15 11:39:39 - Test Accuracy: 37.16%
2025-03-15 11:39:54 - Starting new experiment!
2025-03-15 11:39:54 - Hyperparameters:
2025-03-15 11:39:54 - {
    "model_name": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=2048, out_features=10, bias=True)\n)",
    "pretrained_model": true,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-15 11:40:26 - ==================================================
2025-03-15 11:40:26 - Running script: pretrained_models.py
2025-03-15 11:40:26 - Script started at: 2025-03-15 11:40:26
2025-03-15 11:40:26 - Using device: cuda
2025-03-15 11:40:26 - CUDA Device Total Memory [GB]:50.936283136
2025-03-15 11:40:26 - Starting new experiment!
2025-03-15 11:40:26 - Hyperparameters:
2025-03-15 11:40:26 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-15 11:40:26 - Training model: (ResNet50, pretrained=False)
2025-03-15 11:42:00 - Epoch 1/1, Loss: 2.3904, Accuracy: 21.9067%
2025-03-15 11:42:14 - Test Accuracy: 27.81%
2025-03-15 11:42:28 - Starting new experiment!
2025-03-15 11:42:28 - Hyperparameters:
2025-03-15 11:42:28 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-15 11:42:30 - Training model: (ResNet50, pretrained=True)
2025-03-15 11:43:46 - Epoch 1/1, Loss: 0.7219, Accuracy: 76.9350%
2025-03-15 11:43:58 - Test Accuracy: 81.58%
2025-03-15 11:44:11 - Script ended at: 2025-03-15 11:44:11
2025-03-15 11:44:11 - Total execution time: 225.08 seconds
2025-03-15 11:44:11 - ==================================================
2025-03-15 11:53:17 - ==================================================
2025-03-15 11:53:17 - Running script: pretrained_models.py
2025-03-15 11:53:17 - Script started at: 2025-03-15 11:53:17
2025-03-15 11:53:17 - Using device: cuda
2025-03-15 11:53:17 - CUDA Device Total Memory [GB]:50.936283136
2025-03-15 11:53:17 - Starting new experiment!
2025-03-15 11:53:17 - Hyperparameters:
2025-03-15 11:53:17 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-15 11:53:17 - Training model: (ResNet50, pretrained=False)
2025-03-15 11:54:50 - Epoch 1/10, Loss: 2.4472, Accuracy: 20.7367%
2025-03-15 11:56:21 - Epoch 2/10, Loss: 1.9985, Accuracy: 31.6283%
2025-03-15 11:57:53 - Epoch 3/10, Loss: 1.8073, Accuracy: 36.7300%
2025-03-15 11:59:25 - Epoch 4/10, Loss: 1.6889, Accuracy: 40.7200%
2025-03-15 12:00:56 - Epoch 5/10, Loss: 1.5929, Accuracy: 43.1583%
2025-03-15 12:02:26 - Epoch 6/10, Loss: 1.5377, Accuracy: 44.6967%
2025-03-15 12:03:57 - Epoch 7/10, Loss: 1.4809, Accuracy: 46.8700%
2025-03-15 12:05:30 - Epoch 8/10, Loss: 1.4534, Accuracy: 47.3667%
2025-03-15 12:07:02 - Epoch 9/10, Loss: 1.4315, Accuracy: 48.4133%
2025-03-15 12:08:35 - Epoch 10/10, Loss: 1.4021, Accuracy: 49.4283%
2025-03-15 12:08:49 - Test Accuracy: 54.65%
2025-03-15 12:09:03 - Starting new experiment!
2025-03-15 12:09:03 - Hyperparameters:
2025-03-15 12:09:03 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-15 12:09:03 - Training model: (ResNet50, pretrained=True)
2025-03-15 12:10:20 - Epoch 1/10, Loss: 0.7218, Accuracy: 76.9233%
2025-03-15 12:11:36 - Epoch 2/10, Loss: 0.5012, Accuracy: 82.4867%
2025-03-15 12:12:52 - Epoch 3/10, Loss: 0.4733, Accuracy: 83.7983%
2025-03-15 12:14:08 - Epoch 4/10, Loss: 0.4617, Accuracy: 84.3433%
2025-03-15 12:15:24 - Epoch 5/10, Loss: 0.4552, Accuracy: 84.7483%
2025-03-15 12:16:41 - Epoch 6/10, Loss: 0.4554, Accuracy: 85.2300%
2025-03-15 12:17:58 - Epoch 7/10, Loss: 0.4574, Accuracy: 85.2167%
2025-03-15 12:19:15 - Epoch 8/10, Loss: 0.4579, Accuracy: 85.6900%
2025-03-15 12:20:31 - Epoch 9/10, Loss: 0.4568, Accuracy: 85.6533%
2025-03-15 12:21:48 - Epoch 10/10, Loss: 0.4596, Accuracy: 85.9800%
2025-03-15 12:22:00 - Test Accuracy: 84.61%
2025-03-15 12:22:13 - Script ended at: 2025-03-15 12:22:13
2025-03-15 12:22:13 - Total execution time: 1735.77 seconds
2025-03-15 12:22:13 - ==================================================
2025-03-28 12:51:44 - ==================================================
2025-03-28 12:51:44 - Running script: pretrained_models.py
2025-03-28 12:51:44 - Script started at: 2025-03-28 12:51:44
2025-03-28 12:51:44 - Using device: cuda
2025-03-28 12:51:44 - CUDA Device Total Memory [GB]:25.380061184
2025-03-28 12:51:44 - Starting new experiment!
2025-03-28 12:51:44 - Hyperparameters:
2025-03-28 12:51:44 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-28 12:51:45 - Training model: (ResNet50, pretrained=False)
2025-03-28 12:53:06 - ==================================================
2025-03-28 12:53:06 - Running script: pretrained_models.py
2025-03-28 12:53:06 - Script started at: 2025-03-28 12:53:06
2025-03-28 12:53:06 - Using device: cuda
2025-03-28 12:53:06 - CUDA Device Total Memory [GB]:25.38635264
2025-03-28 12:53:06 - Starting new experiment!
2025-03-28 12:53:06 - Hyperparameters:
2025-03-28 12:53:06 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-28 12:53:06 - Training model: (ResNet50, pretrained=False)
2025-03-28 12:53:38 - ==================================================
2025-03-28 12:53:38 - Running script: pretrained_models.py
2025-03-28 12:53:38 - Script started at: 2025-03-28 12:53:38
2025-03-28 12:53:38 - Using device: cuda
2025-03-28 12:53:38 - CUDA Device Total Memory [GB]:25.38635264
2025-03-28 12:53:38 - Starting new experiment!
2025-03-28 12:53:38 - Hyperparameters:
2025-03-28 12:53:38 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-28 12:53:38 - Training model: (ResNet50, pretrained=False)
2025-03-28 12:55:02 - ==================================================
2025-03-28 12:55:02 - Running script: pretrained_models.py
2025-03-28 12:55:02 - Script started at: 2025-03-28 12:55:02
2025-03-28 12:55:02 - Using device: cuda
2025-03-28 12:55:02 - CUDA Device Total Memory [GB]:25.38635264
2025-03-28 12:55:02 - Starting new experiment!
2025-03-28 12:55:02 - Hyperparameters:
2025-03-28 12:55:02 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "batchSize": 1024,
    "n_epochs": 10,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-28 12:55:02 - Training model: (ResNet50, pretrained=False)
2025-03-28 12:56:16 - ==================================================
2025-03-28 12:56:16 - Running script: pretrained_models.py
2025-03-28 12:56:16 - Script started at: 2025-03-28 12:56:16
2025-03-28 12:56:16 - Using device: cuda
2025-03-28 12:56:16 - CUDA Device Total Memory [GB]:25.38635264
2025-03-28 12:56:16 - Starting new experiment!
2025-03-28 12:56:16 - Hyperparameters:
2025-03-28 12:56:16 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "batchSize": 1024,
    "n_epochs": 10,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-28 12:56:16 - Training model: (ResNet50, pretrained=False)
2025-03-28 12:57:43 - Epoch 1/10, Loss: 2.8196, Accuracy: 11.9450%
2025-03-28 12:59:09 - Epoch 2/10, Loss: 2.7883, Accuracy: 13.5850%
2025-03-28 13:00:35 - Epoch 3/10, Loss: 2.7780, Accuracy: 13.9350%
2025-03-28 13:02:02 - Epoch 4/10, Loss: 2.7696, Accuracy: 14.2600%
2025-03-28 13:03:28 - Epoch 5/10, Loss: 2.7781, Accuracy: 14.4117%
2025-03-28 13:04:55 - Epoch 6/10, Loss: 2.7911, Accuracy: 15.4733%
2025-03-28 13:06:21 - Epoch 7/10, Loss: 2.7877, Accuracy: 15.5833%
2025-03-28 13:07:48 - Epoch 8/10, Loss: 2.7886, Accuracy: 15.5750%
2025-03-28 13:09:14 - Epoch 9/10, Loss: 2.7837, Accuracy: 15.6900%
2025-03-28 13:10:41 - Epoch 10/10, Loss: 2.7729, Accuracy: 15.2233%
2025-03-28 13:10:55 - Test Accuracy: 15.57%
2025-03-28 13:11:08 - Starting new experiment!
2025-03-28 13:11:08 - Hyperparameters:
2025-03-28 13:11:08 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "batchSize": 1024,
    "n_epochs": 10,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-28 13:11:10 - Training model: (ResNet50, pretrained=True)
2025-03-28 13:12:38 - Epoch 1/10, Loss: 1.3146, Accuracy: 67.4433%
2025-03-28 13:14:04 - Epoch 2/10, Loss: 0.7123, Accuracy: 78.4550%
2025-03-28 13:15:31 - Epoch 3/10, Loss: 0.5856, Accuracy: 81.1683%
2025-03-28 13:16:57 - Epoch 4/10, Loss: 0.5288, Accuracy: 82.5200%
2025-03-28 13:18:24 - Epoch 5/10, Loss: 0.4928, Accuracy: 83.5883%
2025-03-28 13:19:51 - Epoch 6/10, Loss: 0.4693, Accuracy: 84.3567%
2025-03-28 13:21:19 - Epoch 7/10, Loss: 0.4490, Accuracy: 84.8517%
2025-03-28 13:22:46 - Epoch 8/10, Loss: 0.4329, Accuracy: 85.2567%
2025-03-28 13:24:13 - Epoch 9/10, Loss: 0.4211, Accuracy: 85.5900%
2025-03-28 13:25:41 - Epoch 10/10, Loss: 0.4115, Accuracy: 86.0067%
2025-03-28 13:25:55 - Test Accuracy: 84.30%
2025-03-28 13:26:09 - Script ended at: 2025-03-28 13:26:09
2025-03-28 13:26:09 - Total execution time: 1793.50 seconds
2025-03-28 13:26:09 - ==================================================
2025-03-31 13:18:44 - ==================================================
2025-03-31 13:18:44 - Running script: pretrained_models.py
2025-03-31 13:18:44 - Script started at: 2025-03-31 13:18:44
2025-03-31 13:18:44 - Using device: cuda
2025-03-31 13:18:44 - CUDA Device Total Memory [GB]:25.380061184
2025-03-31 13:18:44 - Starting new experiment!
2025-03-31 13:18:44 - Hyperparameters:
2025-03-31 13:18:44 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "finetuning": "finetuning",
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-31 13:18:44 - Training model: (ResNet50, pretrained=False)
2025-03-31 13:21:18 - Epoch 1/1, Loss: 2.4583, Accuracy: 20.3450%
2025-03-31 13:21:38 - Test Accuracy: 34.47%
2025-03-31 13:21:59 - Starting new experiment!
2025-03-31 13:21:59 - Hyperparameters:
2025-03-31 13:21:59 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "finetuning": "finetuning",
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-31 13:22:00 - Training model: (ResNet50, pretrained=True)
2025-03-31 13:24:20 - Epoch 1/1, Loss: 0.7228, Accuracy: 76.9500%
2025-03-31 13:24:38 - Test Accuracy: 81.69%
2025-03-31 13:24:57 - Script ended at: 2025-03-31 13:24:57
2025-03-31 13:24:57 - Total execution time: 373.68 seconds
2025-03-31 13:24:57 - ==================================================
2025-03-31 13:37:55 - ==================================================
2025-03-31 13:37:55 - Running script: pretrained_models.py
2025-03-31 13:37:55 - Script started at: 2025-03-31 13:37:55
2025-03-31 13:37:55 - Using device: cuda
2025-03-31 13:37:55 - CUDA Device Total Memory [GB]:25.380061184
2025-03-31 13:37:55 - Starting new experiment!
2025-03-31 13:37:55 - Hyperparameters:
2025-03-31 13:37:55 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-31 13:37:55 - Training model: (ResNet50, pretrained=False)
2025-03-31 13:40:28 - Epoch 1/1, Loss: 2.4387, Accuracy: 20.8183%
2025-03-31 13:40:49 - Test Accuracy: 20.20%
2025-03-31 13:41:09 - Starting new experiment!
2025-03-31 13:41:09 - Hyperparameters:
2025-03-31 13:41:09 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "finetuning": false,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-31 13:41:09 - Training model: (ResNet50, pretrained=False)
2025-03-31 13:43:22 - Epoch 1/1, Loss: 2.3674, Accuracy: 22.7767%
2025-03-31 13:43:44 - Test Accuracy: 32.56%
2025-03-31 13:44:06 - Starting new experiment!
2025-03-31 13:44:06 - Hyperparameters:
2025-03-31 13:44:06 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-31 13:44:06 - Training model: (ResNet50, pretrained=True)
2025-03-31 13:46:27 - Epoch 1/1, Loss: 0.7223, Accuracy: 76.9733%
2025-03-31 13:46:46 - Test Accuracy: 81.37%
2025-03-31 13:47:05 - Starting new experiment!
2025-03-31 13:47:05 - Hyperparameters:
2025-03-31 13:47:05 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "finetuning": false,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001
}
2025-03-31 13:47:05 - Training model: (ResNet50, pretrained=True)
2025-03-31 13:49:06 - Epoch 1/1, Loss: 0.7227, Accuracy: 76.8250%
2025-03-31 13:49:24 - Test Accuracy: 81.39%
2025-03-31 13:49:43 - Script ended at: 2025-03-31 13:49:43
2025-03-31 13:49:43 - Total execution time: 708.51 seconds
2025-03-31 13:49:43 - ==================================================
2025-03-31 13:55:00 - ==================================================
2025-03-31 13:55:00 - Running script: pretrained_models.py
2025-03-31 13:55:00 - Script started at: 2025-03-31 13:55:00
2025-03-31 13:55:00 - Using device: cuda
2025-03-31 13:55:00 - CUDA Device Total Memory [GB]:25.380061184
2025-03-31 13:55:00 - Starting new experiment!
2025-03-31 13:55:00 - Hyperparameters:
2025-03-31 13:55:00 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 13:55:00 - Training model: (ResNet50, pretrained=False)
2025-03-31 13:57:29 - Epoch 1/1, Loss: 2.4444, Accuracy: 20.4567%
2025-03-31 13:57:49 - Test Accuracy: 16.57%
2025-03-31 13:58:08 - Starting new experiment!
2025-03-31 13:58:08 - Hyperparameters:
2025-03-31 13:58:08 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "SGD",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 13:58:08 - Training model: (ResNet50, pretrained=False)
2025-03-31 14:00:27 - Epoch 1/1, Loss: 2.1995, Accuracy: 22.6567%
2025-03-31 14:00:47 - Test Accuracy: 32.01%
2025-03-31 14:01:06 - Starting new experiment!
2025-03-31 14:01:06 - Hyperparameters:
2025-03-31 14:01:06 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "finetuning": false,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 14:01:07 - Training model: (ResNet50, pretrained=False)
2025-03-31 14:03:08 - Epoch 1/1, Loss: 2.4338, Accuracy: 21.1150%
2025-03-31 14:03:28 - Test Accuracy: 18.12%
2025-03-31 14:03:48 - Starting new experiment!
2025-03-31 14:03:48 - Hyperparameters:
2025-03-31 14:03:48 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "finetuning": false,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "SGD",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 14:03:48 - Training model: (ResNet50, pretrained=False)
2025-03-31 14:05:45 - Epoch 1/1, Loss: 2.1618, Accuracy: 22.5650%
2025-03-31 14:06:03 - Test Accuracy: 29.65%
2025-03-31 14:06:22 - Starting new experiment!
2025-03-31 14:06:22 - Hyperparameters:
2025-03-31 14:06:22 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 14:06:22 - Training model: (ResNet50, pretrained=True)
2025-03-31 14:08:47 - Epoch 1/1, Loss: 0.7251, Accuracy: 76.7450%
2025-03-31 14:09:07 - Test Accuracy: 81.39%
2025-03-31 14:09:26 - Starting new experiment!
2025-03-31 14:09:26 - Hyperparameters:
2025-03-31 14:09:26 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "SGD",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 14:09:26 - Training model: (ResNet50, pretrained=True)
2025-03-31 14:11:48 - Epoch 1/1, Loss: 2.1166, Accuracy: 42.8083%
2025-03-31 14:12:07 - Test Accuracy: 60.68%
2025-03-31 14:12:26 - Starting new experiment!
2025-03-31 14:12:26 - Hyperparameters:
2025-03-31 14:12:26 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "finetuning": false,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 14:12:26 - Training model: (ResNet50, pretrained=True)
2025-03-31 14:14:30 - Epoch 1/1, Loss: 0.7259, Accuracy: 76.8000%
2025-03-31 14:14:48 - Test Accuracy: 81.50%
2025-03-31 14:15:06 - Starting new experiment!
2025-03-31 14:15:06 - Hyperparameters:
2025-03-31 14:15:06 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "finetuning": false,
    "batchSize": 64,
    "n_epochs": 1,
    "optimizer": "SGD",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 14:15:06 - Training model: (ResNet50, pretrained=True)
2025-03-31 14:16:58 - Epoch 1/1, Loss: 2.1063, Accuracy: 42.5933%
2025-03-31 14:17:18 - Test Accuracy: 59.56%
2025-03-31 14:17:37 - Script ended at: 2025-03-31 14:17:37
2025-03-31 14:17:37 - Total execution time: 1357.24 seconds
2025-03-31 14:17:37 - ==================================================
2025-03-31 19:12:54 - ==================================================
2025-03-31 19:12:54 - Running script: pretrained_models.py
2025-03-31 19:12:54 - Script started at: 2025-03-31 19:12:54
2025-03-31 19:12:54 - Using device: cuda
2025-03-31 19:12:54 - CUDA Device Total Memory [GB]:25.380061184
2025-03-31 19:12:54 - Starting new experiment!
2025-03-31 19:12:54 - Hyperparameters:
2025-03-31 19:12:54 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 2,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 19:12:54 - Training model: (ResNet50, pretrained=False, finetuning=True, optimizer=Adam)
2025-03-31 19:15:33 - Epoch 1/2, Loss: 2.4948, Accuracy: 19.3067%
2025-03-31 19:18:13 - Epoch 2/2, Loss: 2.0491, Accuracy: 30.4483%
2025-03-31 19:18:34 - Test Accuracy: 21.60%
2025-03-31 19:18:34 - Saved numerical results in pickle!
2025-03-31 19:18:56 - Starting new experiment!
2025-03-31 19:18:56 - Hyperparameters:
2025-03-31 19:18:56 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 2,
    "optimizer": "SGD",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 19:18:56 - Training model: (ResNet50, pretrained=False, finetuning=True, optimizer=SGD)
2025-03-31 19:21:22 - Epoch 1/2, Loss: 2.1931, Accuracy: 22.8217%
2025-03-31 19:23:47 - Epoch 2/2, Loss: 2.0188, Accuracy: 37.4267%
2025-03-31 19:24:06 - Test Accuracy: 42.37%
2025-03-31 19:24:06 - Saved numerical results in pickle!
2025-03-31 19:24:26 - Starting new experiment!
2025-03-31 19:24:26 - Hyperparameters:
2025-03-31 19:24:26 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "finetuning": false,
    "batchSize": 64,
    "n_epochs": 2,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 19:24:27 - Training model: (ResNet50, pretrained=False, finetuning=False, optimizer=Adam)
2025-03-31 19:26:33 - Epoch 1/2, Loss: 2.4451, Accuracy: 20.8633%
2025-03-31 19:28:41 - Epoch 2/2, Loss: 2.0029, Accuracy: 32.0017%
2025-03-31 19:29:01 - Test Accuracy: 26.96%
2025-03-31 19:29:01 - Saved numerical results in pickle!
2025-03-31 19:29:21 - Starting new experiment!
2025-03-31 19:29:21 - Hyperparameters:
2025-03-31 19:29:21 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "finetuning": false,
    "batchSize": 64,
    "n_epochs": 2,
    "optimizer": "SGD",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 19:29:22 - Training model: (ResNet50, pretrained=False, finetuning=False, optimizer=SGD)
2025-03-31 19:31:23 - Epoch 1/2, Loss: 2.1829, Accuracy: 21.2400%
2025-03-31 19:33:26 - Epoch 2/2, Loss: 2.0226, Accuracy: 33.5333%
2025-03-31 19:33:46 - Test Accuracy: 43.48%
2025-03-31 19:33:46 - Saved numerical results in pickle!
2025-03-31 19:34:06 - Starting new experiment!
2025-03-31 19:34:06 - Hyperparameters:
2025-03-31 19:34:06 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 2,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 19:34:06 - Training model: (ResNet50, pretrained=True, finetuning=True, optimizer=Adam)
2025-03-31 19:36:26 - Epoch 1/2, Loss: 0.7211, Accuracy: 76.9667%
2025-03-31 19:38:45 - Epoch 2/2, Loss: 0.5021, Accuracy: 82.2650%
2025-03-31 19:39:04 - Test Accuracy: 82.74%
2025-03-31 19:39:04 - Saved numerical results in pickle!
2025-03-31 19:39:23 - Starting new experiment!
2025-03-31 19:39:23 - Hyperparameters:
2025-03-31 19:39:23 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 2,
    "optimizer": "SGD",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 19:39:23 - Training model: (ResNet50, pretrained=True, finetuning=True, optimizer=SGD)
2025-03-31 19:41:43 - Epoch 1/2, Loss: 2.1190, Accuracy: 41.8050%
2025-03-31 19:43:58 - Epoch 2/2, Loss: 1.8255, Accuracy: 62.8317%
2025-03-31 19:44:16 - Test Accuracy: 65.80%
2025-03-31 19:44:16 - Saved numerical results in pickle!
2025-03-31 19:44:36 - Starting new experiment!
2025-03-31 19:44:36 - Hyperparameters:
2025-03-31 19:44:36 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "finetuning": false,
    "batchSize": 64,
    "n_epochs": 2,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 19:44:36 - Training model: (ResNet50, pretrained=True, finetuning=False, optimizer=Adam)
2025-03-31 19:46:33 - Epoch 1/2, Loss: 0.7257, Accuracy: 76.8333%
2025-03-31 19:48:30 - Epoch 2/2, Loss: 0.5048, Accuracy: 82.2917%
2025-03-31 19:48:48 - Test Accuracy: 82.76%
2025-03-31 19:48:48 - Saved numerical results in pickle!
2025-03-31 19:49:08 - Starting new experiment!
2025-03-31 19:49:08 - Hyperparameters:
2025-03-31 19:49:08 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "finetuning": false,
    "batchSize": 64,
    "n_epochs": 2,
    "optimizer": "SGD",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 19:49:08 - Training model: (ResNet50, pretrained=True, finetuning=False, optimizer=SGD)
2025-03-31 19:51:07 - Epoch 1/2, Loss: 2.0988, Accuracy: 45.3650%
2025-03-31 19:53:33 - Epoch 2/2, Loss: 1.8106, Accuracy: 63.0817%
2025-03-31 19:53:57 - Test Accuracy: 65.95%
2025-03-31 19:53:57 - Saved numerical results in pickle!
2025-03-31 19:54:25 - Script ended at: 2025-03-31 19:54:25
2025-03-31 19:54:25 - Total execution time: 2491.47 seconds
2025-03-31 19:54:25 - ==================================================
2025-03-31 20:16:31 - ==================================================
2025-03-31 20:16:31 - Running script: pretrained_models.py
2025-03-31 20:16:31 - Script started at: 2025-03-31 20:16:31
2025-03-31 20:16:31 - Using device: cuda
2025-03-31 20:16:31 - CUDA Device Total Memory [GB]:25.380061184
2025-03-31 20:16:31 - Starting new experiment!
2025-03-31 20:16:31 - Hyperparameters:
2025-03-31 20:16:31 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 2,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 20:16:32 - Training model: (ResNet50, pretrained=True, finetuning=True, optimizer=Adam)
2025-03-31 20:19:08 - Epoch 1/2, Loss: 0.7227, Accuracy: 77.0250%
2025-03-31 20:21:44 - Epoch 2/2, Loss: 0.5033, Accuracy: 82.3450%
2025-03-31 20:22:05 - Test Accuracy: 81.46%
2025-03-31 20:22:05 - Saved numerical results in pickle!
2025-03-31 20:26:44 - ==================================================
2025-03-31 20:26:44 - Running script: pretrained_models.py
2025-03-31 20:26:44 - Script started at: 2025-03-31 20:26:44
2025-03-31 20:26:44 - Using device: cuda
2025-03-31 20:26:44 - CUDA Device Total Memory [GB]:25.380061184
2025-03-31 20:26:44 - Starting new experiment!
2025-03-31 20:26:44 - Hyperparameters:
2025-03-31 20:26:44 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 2,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 20:26:45 - Training model: (ResNet50, pretrained=True, finetuning=True, optimizer=Adam)
2025-03-31 20:29:21 - ==================================================
2025-03-31 20:29:21 - Running script: pretrained_models.py
2025-03-31 20:29:21 - Script started at: 2025-03-31 20:29:21
2025-03-31 20:29:21 - Using device: cuda
2025-03-31 20:29:21 - CUDA Device Total Memory [GB]:25.380061184
2025-03-31 20:29:21 - Starting new experiment!
2025-03-31 20:29:21 - Hyperparameters:
2025-03-31 20:29:21 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 2,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 20:29:21 - Training model: (ResNet50, pretrained=True, finetuning=True, optimizer=Adam)
2025-03-31 20:30:30 - ==================================================
2025-03-31 20:30:30 - Running script: pretrained_models.py
2025-03-31 20:30:30 - Script started at: 2025-03-31 20:30:30
2025-03-31 20:30:30 - Using device: cuda
2025-03-31 20:30:30 - CUDA Device Total Memory [GB]:25.380061184
2025-03-31 20:30:30 - Starting new experiment!
2025-03-31 20:30:30 - Hyperparameters:
2025-03-31 20:30:30 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 2,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 20:30:30 - Training model: (ResNet50, pretrained=True, finetuning=True, optimizer=Adam)
2025-03-31 20:33:04 - Epoch 1/2, Loss: 0.7260, Accuracy: 76.8867%
2025-03-31 20:35:40 - Epoch 2/2, Loss: 0.5000, Accuracy: 82.5583%
2025-03-31 20:36:01 - Test Accuracy: 82.66%
2025-03-31 20:36:01 - Saved numerical results in pickle!
2025-03-31 20:38:09 - ==================================================
2025-03-31 20:38:09 - Running script: pretrained_models.py
2025-03-31 20:38:09 - Script started at: 2025-03-31 20:38:09
2025-03-31 20:38:09 - Using device: cuda
2025-03-31 20:38:09 - CUDA Device Total Memory [GB]:25.380061184
2025-03-31 20:38:09 - Starting new experiment!
2025-03-31 20:38:09 - Hyperparameters:
2025-03-31 20:38:09 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 2,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 20:38:10 - Training model: (ResNet50, pretrained=True, finetuning=True, optimizer=Adam)
2025-03-31 20:38:33 - ==================================================
2025-03-31 20:38:33 - Running script: pretrained_models.py
2025-03-31 20:38:33 - Script started at: 2025-03-31 20:38:33
2025-03-31 20:38:33 - Using device: cuda
2025-03-31 20:38:33 - CUDA Device Total Memory [GB]:25.380061184
2025-03-31 20:38:33 - Starting new experiment!
2025-03-31 20:38:33 - Hyperparameters:
2025-03-31 20:38:33 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 2,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 20:38:34 - Training model: (ResNet50, pretrained=True, finetuning=True, optimizer=Adam)
2025-03-31 20:41:09 - Epoch 1/2, Loss: 0.7218, Accuracy: 76.9633%
2025-03-31 20:43:43 - Epoch 2/2, Loss: 0.5023, Accuracy: 82.4350%
2025-03-31 20:44:03 - Test Accuracy: 83.02%
2025-03-31 20:44:03 - Saved numerical results in pickle!
2025-03-31 20:44:26 - Saved numerical results in pickle!
2025-03-31 20:44:26 - Script ended at: 2025-03-31 20:44:26
2025-03-31 20:44:26 - Total execution time: 352.97 seconds
2025-03-31 20:44:26 - ==================================================
2025-03-31 20:52:10 - ==================================================
2025-03-31 20:52:10 - Running script: pretrained_models.py
2025-03-31 20:52:10 - Script started at: 2025-03-31 20:52:10
2025-03-31 20:52:10 - Using device: cuda
2025-03-31 20:52:10 - CUDA Device Total Memory [GB]:25.380061184
2025-03-31 20:52:10 - Starting new experiment!
2025-03-31 20:52:10 - Hyperparameters:
2025-03-31 20:52:10 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 2,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 20:52:11 - Training model: (ResNet50, pretrained=True, finetuning=True, optimizer=Adam)
2025-03-31 20:54:48 - Epoch 1/2, Loss: 0.7234, Accuracy: 77.0217%
2025-03-31 20:57:23 - Epoch 2/2, Loss: 0.4999, Accuracy: 82.5567%
2025-03-31 20:57:44 - Test Accuracy: 82.85%
2025-03-31 20:57:44 - Saved numerical results in pickle!
2025-03-31 20:58:07 - Starting new experiment!
2025-03-31 20:58:07 - Hyperparameters:
2025-03-31 20:58:07 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "finetuning": false,
    "batchSize": 64,
    "n_epochs": 2,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 20:58:07 - Training model: (ResNet50, pretrained=True, finetuning=False, optimizer=Adam)
2025-03-31 21:00:08 - Epoch 1/2, Loss: 0.7250, Accuracy: 76.8767%
2025-03-31 21:02:09 - Epoch 2/2, Loss: 0.5016, Accuracy: 82.4317%
2025-03-31 21:02:28 - Test Accuracy: 82.72%
2025-03-31 21:02:28 - Saved numerical results in pickle!
2025-03-31 21:02:50 - Saved numerical results in pickle!
2025-03-31 21:02:50 - Script ended at: 2025-03-31 21:02:50
2025-03-31 21:02:50 - Total execution time: 639.75 seconds
2025-03-31 21:02:50 - ==================================================
2025-03-31 21:03:51 - ==================================================
2025-03-31 21:03:51 - Running script: pretrained_models.py
2025-03-31 21:03:51 - Script started at: 2025-03-31 21:03:51
2025-03-31 21:03:51 - Using device: cuda
2025-03-31 21:03:51 - CUDA Device Total Memory [GB]:25.380061184
2025-03-31 21:03:51 - Starting new experiment!
2025-03-31 21:03:51 - Hyperparameters:
2025-03-31 21:03:51 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 2,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 21:03:51 - Training model: (ResNet50, pretrained=True, finetuning=True, optimizer=Adam)
2025-03-31 21:06:25 - Epoch 1/2, Loss: 0.7236, Accuracy: 76.7500%
2025-03-31 21:09:01 - Epoch 2/2, Loss: 0.5026, Accuracy: 82.4450%
2025-03-31 21:09:21 - Test Accuracy: 82.88%
2025-03-31 21:09:21 - Saved numerical results in pickle!
2025-03-31 21:09:44 - Starting new experiment!
2025-03-31 21:09:44 - Hyperparameters:
2025-03-31 21:09:44 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "finetuning": false,
    "batchSize": 64,
    "n_epochs": 2,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-03-31 21:09:44 - Training model: (ResNet50, pretrained=True, finetuning=False, optimizer=Adam)
2025-03-31 21:11:45 - Epoch 1/2, Loss: 0.7257, Accuracy: 76.7883%
2025-03-31 21:13:48 - Epoch 2/2, Loss: 0.5023, Accuracy: 82.3750%
2025-03-31 21:14:07 - Test Accuracy: 82.53%
2025-03-31 21:14:07 - Saved numerical results in pickle!
2025-03-31 21:14:28 - Saved numerical results in pickle!
2025-03-31 21:14:28 - Script ended at: 2025-03-31 21:14:28
2025-03-31 21:14:28 - Total execution time: 637.34 seconds
2025-03-31 21:14:28 - ==================================================
2025-04-02 06:24:52 - ==================================================
2025-04-02 06:24:52 - Running script: pretrained_models.py
2025-04-02 06:24:52 - Script started at: 2025-04-02 06:24:52
2025-04-02 06:24:52 - Using device: cuda
2025-04-02 06:24:52 - CUDA Device Total Memory [GB]:50.936283136
2025-04-02 06:24:52 - Starting new experiment!
2025-04-02 06:24:52 - Hyperparameters:
2025-04-02 06:24:52 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 2,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-02 06:24:52 - Training model: (ResNet50, pretrained=True, finetuning=True, optimizer=Adam)
2025-04-02 06:26:31 - Epoch 1/2, Loss: 0.7239, Accuracy: 76.9667%
2025-04-02 06:28:09 - Epoch 2/2, Loss: 0.5019, Accuracy: 82.4267%
2025-04-02 06:28:22 - Test Accuracy: 82.87%
2025-04-02 06:32:36 - ==================================================
2025-04-02 06:32:36 - Running script: pretrained_models.py
2025-04-02 06:32:36 - Script started at: 2025-04-02 06:32:36
2025-04-02 06:32:36 - Using device: cuda
2025-04-02 06:32:36 - CUDA Device Total Memory [GB]:50.936283136
2025-04-02 06:32:36 - Starting new experiment!
2025-04-02 06:32:36 - Hyperparameters:
2025-04-02 06:32:36 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 2,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-02 06:32:37 - Training model: (ResNet50, pretrained=True, finetuning=True, optimizer=Adam)
2025-04-02 06:33:43 - ==================================================
2025-04-02 06:33:43 - Running script: pretrained_models.py
2025-04-02 06:33:43 - Script started at: 2025-04-02 06:33:43
2025-04-02 06:33:43 - Using device: cuda
2025-04-02 06:33:43 - CUDA Device Total Memory [GB]:50.936283136
2025-04-02 06:33:43 - Starting new experiment!
2025-04-02 06:33:43 - Hyperparameters:
2025-04-02 06:33:43 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-02 06:33:44 - Training model: (ResNet50, pretrained=True, finetuning=True, optimizer=Adam)
2025-04-02 06:35:23 - Epoch 1/10, Loss: 0.7264, Accuracy: 76.8683%
2025-04-02 06:37:01 - Epoch 2/10, Loss: 0.5013, Accuracy: 82.5050%
2025-04-02 06:38:40 - Epoch 3/10, Loss: 0.4728, Accuracy: 83.6867%
2025-04-02 06:40:19 - Epoch 4/10, Loss: 0.4601, Accuracy: 84.3917%
2025-04-02 06:41:58 - Epoch 5/10, Loss: 0.4546, Accuracy: 84.9067%
2025-04-02 06:43:37 - Epoch 6/10, Loss: 0.4526, Accuracy: 85.2483%
2025-04-02 06:45:16 - Epoch 7/10, Loss: 0.4580, Accuracy: 85.4867%
2025-04-02 06:46:54 - Epoch 8/10, Loss: 0.4566, Accuracy: 85.6900%
2025-04-02 06:48:33 - Epoch 9/10, Loss: 0.4591, Accuracy: 85.8133%
2025-04-02 06:50:12 - Epoch 10/10, Loss: 0.4596, Accuracy: 85.9050%
2025-04-02 06:50:25 - Test Accuracy: 84.04%
2025-04-02 06:50:25 - Saved numerical results in pickle!
2025-04-02 06:50:41 - Starting new experiment!
2025-04-02 06:50:41 - Hyperparameters:
2025-04-02 06:50:41 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "finetuning": false,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-02 06:50:41 - Training model: (ResNet50, pretrained=True, finetuning=False, optimizer=Adam)
2025-04-02 06:52:00 - Epoch 1/10, Loss: 0.7203, Accuracy: 76.9600%
2025-04-02 06:53:18 - Epoch 2/10, Loss: 0.4994, Accuracy: 82.4733%
2025-04-02 06:54:37 - Epoch 3/10, Loss: 0.4716, Accuracy: 83.8500%
2025-04-02 06:55:55 - Epoch 4/10, Loss: 0.4589, Accuracy: 84.4150%
2025-04-02 06:57:14 - Epoch 5/10, Loss: 0.4554, Accuracy: 84.8783%
2025-04-02 06:58:33 - Epoch 6/10, Loss: 0.4532, Accuracy: 85.1967%
2025-04-02 06:59:51 - Epoch 7/10, Loss: 0.4520, Accuracy: 85.4867%
2025-04-02 07:01:10 - Epoch 8/10, Loss: 0.4581, Accuracy: 85.6317%
2025-04-02 07:02:28 - Epoch 9/10, Loss: 0.4584, Accuracy: 85.6783%
2025-04-02 07:03:47 - Epoch 10/10, Loss: 0.4614, Accuracy: 85.9067%
2025-04-02 07:03:59 - Test Accuracy: 84.17%
2025-04-02 07:03:59 - Saved numerical results in pickle!
2025-04-02 07:04:13 - Saved numerical results in pickle!
2025-04-02 07:04:13 - Script ended at: 2025-04-02 07:04:13
2025-04-02 07:04:13 - Total execution time: 1829.82 seconds
2025-04-02 07:04:13 - ==================================================
2025-04-02 08:45:19 - ==================================================
2025-04-02 08:45:19 - Running script: pretrained_models.py
2025-04-02 08:45:19 - Script started at: 2025-04-02 08:45:19
2025-04-02 08:45:20 - Using device: cuda
2025-04-02 08:45:20 - CUDA Device Total Memory [GB]:50.936283136
2025-04-02 08:45:20 - Starting new experiment!
2025-04-02 08:45:20 - Hyperparameters:
2025-04-02 08:45:20 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-02 08:45:20 - Training model: (ResNet50, pretrained=False, finetuning=True, optimizer=Adam)
2025-04-02 08:46:58 - Epoch 1/10, Loss: 2.4552, Accuracy: 20.3433%
2025-04-02 08:48:34 - Epoch 2/10, Loss: 2.0188, Accuracy: 30.8867%
2025-04-02 08:50:12 - Epoch 3/10, Loss: 1.8242, Accuracy: 35.8467%
2025-04-02 08:51:49 - Epoch 4/10, Loss: 1.7032, Accuracy: 39.6883%
2025-04-02 08:53:27 - Epoch 5/10, Loss: 1.6275, Accuracy: 41.7700%
2025-04-02 08:55:05 - Epoch 6/10, Loss: 1.5585, Accuracy: 43.7550%
2025-04-02 08:56:43 - Epoch 7/10, Loss: 1.5151, Accuracy: 45.1067%
2025-04-02 08:58:22 - Epoch 8/10, Loss: 1.4781, Accuracy: 46.6167%
2025-04-02 09:00:00 - Epoch 9/10, Loss: 1.4444, Accuracy: 47.9133%
2025-04-02 09:01:38 - Epoch 10/10, Loss: 1.4182, Accuracy: 48.8867%
2025-04-02 09:01:51 - Test Accuracy: 43.45%
2025-04-02 09:01:51 - Saved numerical results in pickle!
2025-04-02 09:02:07 - Starting new experiment!
2025-04-02 09:02:07 - Hyperparameters:
2025-04-02 09:02:07 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "SGD",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-02 09:02:07 - Training model: (ResNet50, pretrained=False, finetuning=True, optimizer=SGD)
2025-04-02 09:03:37 - Epoch 1/10, Loss: 2.1821, Accuracy: 24.6633%
2025-04-02 09:05:06 - Epoch 2/10, Loss: 2.0073, Accuracy: 38.6233%
2025-04-02 09:06:36 - Epoch 3/10, Loss: 1.8887, Accuracy: 44.4650%
2025-04-02 09:08:06 - Epoch 4/10, Loss: 1.8069, Accuracy: 47.5783%
2025-04-02 09:09:36 - Epoch 5/10, Loss: 1.7454, Accuracy: 49.5417%
2025-04-02 09:11:06 - Epoch 6/10, Loss: 1.6959, Accuracy: 51.0300%
2025-04-02 09:12:36 - Epoch 7/10, Loss: 1.6617, Accuracy: 52.1017%
2025-04-02 09:14:06 - Epoch 8/10, Loss: 1.6318, Accuracy: 52.9033%
2025-04-02 09:15:37 - Epoch 9/10, Loss: 1.6093, Accuracy: 53.4183%
2025-04-02 09:17:07 - Epoch 10/10, Loss: 1.5912, Accuracy: 53.8900%
2025-04-02 09:17:20 - Test Accuracy: 54.02%
2025-04-02 09:17:20 - Saved numerical results in pickle!
2025-04-02 09:17:34 - Starting new experiment!
2025-04-02 09:17:34 - Hyperparameters:
2025-04-02 09:17:34 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "finetuning": false,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-02 09:17:34 - Training model: (ResNet50, pretrained=False, finetuning=False, optimizer=Adam)
2025-04-02 09:18:56 - Epoch 1/10, Loss: 2.4433, Accuracy: 20.5500%
2025-04-02 09:20:18 - Epoch 2/10, Loss: 2.0227, Accuracy: 30.8783%
2025-04-02 09:21:40 - Epoch 3/10, Loss: 1.8144, Accuracy: 36.5633%
2025-04-02 09:23:02 - Epoch 4/10, Loss: 1.6988, Accuracy: 39.3633%
2025-04-02 09:24:24 - Epoch 5/10, Loss: 1.6176, Accuracy: 42.3117%
2025-04-02 09:25:47 - Epoch 6/10, Loss: 1.5571, Accuracy: 43.6167%
2025-04-02 09:27:09 - Epoch 7/10, Loss: 1.5085, Accuracy: 45.7050%
2025-04-02 09:28:31 - Epoch 8/10, Loss: 1.4818, Accuracy: 46.7017%
2025-04-02 09:29:53 - Epoch 9/10, Loss: 1.4406, Accuracy: 47.9383%
2025-04-02 09:31:15 - Epoch 10/10, Loss: 1.4147, Accuracy: 48.8633%
2025-04-02 09:31:28 - Test Accuracy: 43.86%
2025-04-02 09:31:28 - Saved numerical results in pickle!
2025-04-02 09:31:43 - Starting new experiment!
2025-04-02 09:31:43 - Hyperparameters:
2025-04-02 09:31:43 - {
    "model_name": "ResNet50",
    "pretrained_model": false,
    "finetuning": false,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "SGD",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-02 09:31:43 - Training model: (ResNet50, pretrained=False, finetuning=False, optimizer=SGD)
2025-04-02 09:33:05 - Epoch 1/10, Loss: 2.1488, Accuracy: 24.1567%
2025-04-02 09:34:26 - Epoch 2/10, Loss: 1.9849, Accuracy: 35.5583%
2025-04-02 09:35:48 - Epoch 3/10, Loss: 1.8750, Accuracy: 42.2067%
2025-04-02 09:37:10 - Epoch 4/10, Loss: 1.7941, Accuracy: 46.2417%
2025-04-02 09:38:32 - Epoch 5/10, Loss: 1.7334, Accuracy: 48.6950%
2025-04-02 09:39:53 - Epoch 6/10, Loss: 1.6887, Accuracy: 50.5900%
2025-04-02 09:41:15 - Epoch 7/10, Loss: 1.6509, Accuracy: 51.7617%
2025-04-02 09:42:37 - Epoch 8/10, Loss: 1.6217, Accuracy: 52.9467%
2025-04-02 09:43:58 - Epoch 9/10, Loss: 1.5991, Accuracy: 53.6467%
2025-04-02 09:45:20 - Epoch 10/10, Loss: 1.5803, Accuracy: 54.1583%
2025-04-02 09:45:33 - Test Accuracy: 53.97%
2025-04-02 09:45:33 - Saved numerical results in pickle!
2025-04-02 09:45:47 - Starting new experiment!
2025-04-02 09:45:47 - Hyperparameters:
2025-04-02 09:45:47 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-02 09:45:47 - Training model: (ResNet50, pretrained=True, finetuning=True, optimizer=Adam)
2025-04-02 09:47:13 - Epoch 1/10, Loss: 0.7244, Accuracy: 76.9933%
2025-04-02 09:48:38 - Epoch 2/10, Loss: 0.5013, Accuracy: 82.2617%
2025-04-02 09:50:03 - Epoch 3/10, Loss: 0.4732, Accuracy: 83.6617%
2025-04-02 09:51:28 - Epoch 4/10, Loss: 0.4595, Accuracy: 84.3850%
2025-04-02 09:52:54 - Epoch 5/10, Loss: 0.4559, Accuracy: 84.8400%
2025-04-02 09:54:19 - Epoch 6/10, Loss: 0.4538, Accuracy: 85.1650%
2025-04-02 09:55:44 - Epoch 7/10, Loss: 0.4548, Accuracy: 85.4567%
2025-04-02 09:57:10 - Epoch 8/10, Loss: 0.4577, Accuracy: 85.6033%
2025-04-02 09:58:35 - Epoch 9/10, Loss: 0.4533, Accuracy: 85.8250%
2025-04-02 10:00:01 - Epoch 10/10, Loss: 0.4578, Accuracy: 85.8617%
2025-04-02 10:00:13 - Test Accuracy: 84.62%
2025-04-02 10:00:13 - Saved numerical results in pickle!
2025-04-02 10:00:26 - Starting new experiment!
2025-04-02 10:00:26 - Hyperparameters:
2025-04-02 10:00:26 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "finetuning": true,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "SGD",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-02 10:00:27 - Training model: (ResNet50, pretrained=True, finetuning=True, optimizer=SGD)
2025-04-02 10:01:53 - Epoch 1/10, Loss: 2.1203, Accuracy: 42.3883%
2025-04-02 10:03:19 - Epoch 2/10, Loss: 1.8254, Accuracy: 62.9967%
2025-04-02 10:04:45 - Epoch 3/10, Loss: 1.6375, Accuracy: 66.8683%
2025-04-02 10:06:11 - Epoch 4/10, Loss: 1.5131, Accuracy: 68.6267%
2025-04-02 10:07:36 - Epoch 5/10, Loss: 1.4233, Accuracy: 69.9133%
2025-04-02 10:09:02 - Epoch 6/10, Loss: 1.3613, Accuracy: 70.8433%
2025-04-02 10:10:28 - Epoch 7/10, Loss: 1.3153, Accuracy: 71.2650%
2025-04-02 10:11:54 - Epoch 8/10, Loss: 1.2770, Accuracy: 72.0233%
2025-04-02 10:13:19 - Epoch 9/10, Loss: 1.2503, Accuracy: 72.5483%
2025-04-02 10:14:45 - Epoch 10/10, Loss: 1.2269, Accuracy: 72.9117%
2025-04-02 10:14:58 - Test Accuracy: 73.38%
2025-04-02 10:14:58 - Saved numerical results in pickle!
2025-04-02 10:15:11 - Starting new experiment!
2025-04-02 10:15:11 - Hyperparameters:
2025-04-02 10:15:11 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "finetuning": false,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "Adam",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-02 10:15:12 - Training model: (ResNet50, pretrained=True, finetuning=False, optimizer=Adam)
2025-04-02 10:16:29 - Epoch 1/10, Loss: 0.7223, Accuracy: 77.0217%
2025-04-02 10:17:47 - Epoch 2/10, Loss: 0.5010, Accuracy: 82.4600%
2025-04-02 10:19:05 - Epoch 3/10, Loss: 0.4705, Accuracy: 83.7483%
2025-04-02 10:20:23 - Epoch 4/10, Loss: 0.4582, Accuracy: 84.4450%
2025-04-02 10:21:41 - Epoch 5/10, Loss: 0.4561, Accuracy: 84.9433%
2025-04-02 10:22:59 - Epoch 6/10, Loss: 0.4559, Accuracy: 85.1617%
2025-04-02 10:24:16 - Epoch 7/10, Loss: 0.4521, Accuracy: 85.4900%
2025-04-02 10:25:34 - Epoch 8/10, Loss: 0.4563, Accuracy: 85.5067%
2025-04-02 10:26:52 - Epoch 9/10, Loss: 0.4577, Accuracy: 85.7650%
2025-04-02 10:28:10 - Epoch 10/10, Loss: 0.4597, Accuracy: 85.7783%
2025-04-02 10:28:23 - Test Accuracy: 84.37%
2025-04-02 10:28:23 - Saved numerical results in pickle!
2025-04-02 10:28:36 - Starting new experiment!
2025-04-02 10:28:36 - Hyperparameters:
2025-04-02 10:28:36 - {
    "model_name": "ResNet50",
    "pretrained_model": true,
    "finetuning": false,
    "batchSize": 64,
    "n_epochs": 10,
    "optimizer": "SGD",
    "lr": 0.001,
    "momentum": 0.9,
    "weight_decay": 0.1
}
2025-04-02 10:28:36 - Training model: (ResNet50, pretrained=True, finetuning=False, optimizer=SGD)
2025-04-02 10:29:55 - Epoch 1/10, Loss: 2.1083, Accuracy: 44.0583%
2025-04-02 10:31:13 - Epoch 2/10, Loss: 1.8182, Accuracy: 63.4233%
2025-04-02 10:32:32 - Epoch 3/10, Loss: 1.6321, Accuracy: 66.7850%
2025-04-02 10:33:51 - Epoch 4/10, Loss: 1.5081, Accuracy: 68.7617%
